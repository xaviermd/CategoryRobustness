{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "A1 COMP762_TFIDF_and_POS",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HsHPaICIIUZ"
      },
      "source": [
        "#Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkAynIuemiS0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2da72924-b04a-4698-e65d-5b58b2f94505"
      },
      "source": [
        "#@title Google Drive {run: \"auto\"}\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "drive_folder = \"COMP762_IntentionMining\" # @param {type:\"string\"}\n",
        "drive_folder = os.path.join(\"/gdrive/My Drive/\", drive_folder)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak6SlfzSbgng",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a0717671-b57d-4997-e77b-ccd459b7ba51"
      },
      "source": [
        "# @title Download datasets from Google Drive, and define Sentence, Token, GetAllText() and GetTextByCategories() {display-mode: \"form\"}\n",
        " \n",
        "import os\n",
        "import gdown\n",
        "import json\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        " \n",
        "class Token:\n",
        "  def __init__(self, default_format, properties):\n",
        "    if not callable(default_format):\n",
        "      self.default_format = lambda: default_format\n",
        "    else:\n",
        "      self.default_format = default_format\n",
        "    self.properties = properties\n",
        "  \n",
        "  def __getitem__(self, ix):\n",
        "    return self.properties.__getitem__(ix)\n",
        " \n",
        "  def __setitem__(self, ix, val):\n",
        "    return self.properties.__setitem__(ix, val)\n",
        " \n",
        "  def to_string(self, format_):\n",
        "    return format_.format(**self.properties)\n",
        " \n",
        "  def __string_rep(self):\n",
        "    return self.to_string(self.default_format())\n",
        " \n",
        "  def __str__(self):\n",
        "    return self.__string_rep()\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return self.__str__() + \": \" + self.properties.__repr__()\n",
        " \n",
        "  def __hash__(self):\n",
        "    return self.__string_rep().__hash__()\n",
        " \n",
        "  def __eq__(self, other):\n",
        "    return self.__string_rep() == other.__string_rep()\n",
        "  \n",
        "  def __gt__(self, other):\n",
        "    return self.__string_rep() > other.__string_rep()\n",
        "    \n",
        "  def __lt__(self, other):\n",
        "    return self.__string_rep() < other.__string_rep()\n",
        " \n",
        " \n",
        "class Sentence:\n",
        "  def __init__(self, json_, fmt, get_ancestor):\n",
        "    self.json = {**json_}\n",
        "    self.fmt = fmt\n",
        "    # Lowercase lemmata (plural of lemma)\n",
        "    for t in self.json['tokens']:\n",
        "      t['lemma'] = t['lemma'].lower()\n",
        "    # Create tokens\n",
        "    self.tokens = \\\n",
        "    [\n",
        "      Token(self.getFormat, token) \n",
        "      for token in self.json['tokens']\n",
        "    ]\n",
        "    # Find each token's ancestor\n",
        "    if get_ancestor:\n",
        "      tree = self.makeParseTree()\n",
        "      for ix, token in enumerate(self.tokens):\n",
        "        tree_ix = tree.leaf_treeposition(ix)\n",
        "        token[\"ancestor\"] = tree[tree_ix[:-2]].label()\n",
        "  \n",
        "  def __getitem__(self, ix):\n",
        "    return self.tokens[ix]\n",
        "  \n",
        "  def __setitem__(self, ix, val):\n",
        "    self.tokens[ix] = val\n",
        " \n",
        "  def getFormat(self):\n",
        "    return self.fmt\n",
        "  \n",
        "  def setFormat(self, newFmt):\n",
        "    self.fmt = newFmt\n",
        "  \n",
        "  def withoutPunctuation(self):\n",
        "    without = Sentence({**self.json}, self.getFormat(), False)\n",
        "    # Remove punctuation from parse\n",
        "    parse = self.json[\"parse\"]\n",
        "    punct_ix = list(re.finditer(\"\\([^a-zA-Z0-9(]\\S* \\S*[^a-zA-Z0-9)]\\)\", parse))\n",
        "    for m in reversed(punct_ix):\n",
        "      parse = parse[:m.start()]+ parse[m.end():]\n",
        "    without.json[\"parse\"] = parse\n",
        "    # Remove punctuation from tokens\n",
        "    tokens = []\n",
        "    for ix, t in enumerate(self.tokens):\n",
        "      if t[\"pos\"][0].isalpha():\n",
        "        tokens.append(Token(without.getFormat, {**t.properties}))\n",
        "      elif 0 < len(tokens):\n",
        "        tokens[-1][\"after\"] += t[\"after\"]\n",
        "    without.tokens = tokens\n",
        "    # Done, leave the other fields untouched\n",
        "    return without\n",
        " \n",
        "  def withoutStopWords(self):\n",
        "    without = Sentence({**self.json}, self.getFormat(), False)\n",
        "    # Remove stopwords from tokens\n",
        "    tokens = []\n",
        "    for ix, t in enumerate(self.tokens):\n",
        "      if t[\"lemma\"].lower() not in stopwords.words('english'):\n",
        "        tokens.append(Token(without.getFormat, {**t.properties}))\n",
        "    without.tokens = tokens\n",
        "    # Done, leave the other fields untouched\n",
        "    return without\n",
        " \n",
        "  def makeParseTree(self):\n",
        "    from nltk.tree import Tree\n",
        "    parse = self.json['parse']\n",
        "    # Replace words with indices in parse string\n",
        "    indices = list(enumerate(re.finditer('\\s[^ )]+\\)', parse)))\n",
        "    for ix, match in reversed(indices):\n",
        "      parse = parse[:match.start() + 1] + str(ix) + parse[match.end()-1:]\n",
        "    # Use parse string to create a tree\n",
        "    tree = Tree.fromstring(parse)\n",
        "    # Replace indices in tree with tokens\n",
        "    for lix, leaf in enumerate([leaf for leaf in tree.leaves() if leaf.isnumeric()]):\n",
        "      tree[tree.leaf_treeposition(lix)] = self.tokens[int(leaf)]\n",
        "    return tree\n",
        "  \n",
        "  def to_string(self, fmt=None, after=None):\n",
        "    if fmt is None:\n",
        "      fmt = self.fmt\n",
        "    out = ''\n",
        "    for t in self.tokens:\n",
        "      out += t.to_string(fmt) + (t[\"after\"] if after is None else after)\n",
        "    return out\n",
        " \n",
        "  def __str__(self):\n",
        "    return self.to_string()\n",
        "  \n",
        "  def __repr__(self):\n",
        "    return self.__str__().strip() + \": \" + repr(self.json)\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.tokens)\n",
        " \n",
        "  @staticmethod\n",
        "  def __findLabelInTree(tree, label):\n",
        "    return [p for p in tree.treepositions() if isinstance(tree[p], nltk.tree.Tree) and label == tree[p].label()]\n",
        "  \n",
        "  @staticmethod\n",
        "  def __getParseStringFromTreeWithTokens(tree):\n",
        "    tree_copy = tree.copy(deep=True)\n",
        "    for lix in range(len(tree_copy.leaves())):\n",
        "      tree_copy[tree_copy.leaf_treeposition(lix)] = \\\n",
        "        tree_copy[tree_copy.leaf_treeposition(lix)].to_string(\"{originalText}\")\n",
        "    return str(tree_copy)\n",
        "  \n",
        "  @staticmethod\n",
        "  def __treeToSentence(tree, fmt):\n",
        "    return Sentence(\n",
        "      {\n",
        "        \"parse\": Sentence.__getParseStringFromTreeWithTokens(tree),\n",
        "        \"tokens\": [token.properties for token in tree.leaves()]\n",
        "      },\n",
        "      fmt, False\n",
        "    )\n",
        "  \n",
        "  @staticmethod\n",
        "  def SwapPhrases(sentence_1, sentence_2, label, prefix=None, suffix=None):\n",
        "    import numpy\n",
        "    \n",
        "    # Build a tree from each sentence\n",
        "    tree_1 = sentence_1.makeParseTree()\n",
        "    tree_2 = sentence_2.makeParseTree()\n",
        "    # Find phrase in both trees\n",
        "    tree_1_phrases = Sentence.__findLabelInTree(tree_1, label)\n",
        "    tree_2_phrases = Sentence.__findLabelInTree(tree_2, label)\n",
        "    # If there is nothing to swap, return\n",
        "    if 0 == len(tree_1_phrases) or 0 == len(tree_2_phrases):\n",
        "      return (None, None)\n",
        "    # Pick a phrase at random from each sentence\n",
        "    tree_1_index = tree_1_phrases[np.random.randint(len(tree_1_phrases))]\n",
        "    tree_2_index = tree_2_phrases[np.random.randint(len(tree_2_phrases))]\n",
        "    # DEBUG #\n",
        "    if prefix is not None:\n",
        "      if isinstance(prefix, str):\n",
        "        prefix = [prefix, prefix]\n",
        "      keys = [\"originalText\", \"lemma\"]\n",
        "      for k in keys:\n",
        "        tree_1[tree_1_index].leaves()[0][k] = \\\n",
        "          prefix[0] + tree_1[tree_1_index].leaves()[0][k]\n",
        "        tree_2[tree_2_index].leaves()[0][k] = \\\n",
        "          prefix[1] + tree_2[tree_2_index].leaves()[0][k]\n",
        "    if suffix is not None:\n",
        "      if isinstance(suffix, str):\n",
        "        suffix = [suffix, suffix]\n",
        "      keys = [\"originalText\", \"lemma\"]\n",
        "      for k in keys:\n",
        "        tree_1[tree_1_index].leaves()[-1][k] = \\\n",
        "          tree_1[tree_1_index].leaves()[-1][k] + suffix[0]\n",
        "        tree_2[tree_2_index].leaves()[-1][k] = \\\n",
        "          tree_2[tree_2_index].leaves()[-1][k] + suffix[1]\n",
        "    #########\n",
        "    # Swap\n",
        "    swap = tree_1[tree_1_index]\n",
        "    tree_1[tree_1_index] = tree_2[tree_2_index]\n",
        "    tree_2[tree_2_index] = swap\n",
        "    # Create Sentences\n",
        "    #   Create copy, convert leaves to strings (lemma), and get parse string\n",
        "    return \\\n",
        "    (\n",
        "      Sentence.__treeToSentence(tree_1, sentence_1.fmt),\n",
        "      Sentence.__treeToSentence(tree_2, sentence_2.fmt)\n",
        "    )\n",
        " \n",
        " \n",
        "archive = \"Automating-Intention-Mining-parsed-data.tar.gz\"\n",
        "url = \"https://drive.google.com/uc?id=1MYR04EN9wyEw5C-RhpAmX5Xnat-jiBSy\"\n",
        "print(\"Downloading {}: \".format(archive), end=\"\")\n",
        "if not os.path.isfile(archive):\n",
        "  gdown.download(url, archive, 0)\n",
        "else:\n",
        "  print('file already exists. Skipping download.')\n",
        "print(\"done\")\n",
        " \n",
        "# Remove old paths\n",
        "parsed_folder = 'parsed'\n",
        "if os.path.exists(parsed_folder):\n",
        "  !rm -r parsed\n",
        " \n",
        "print(\"Extracting files... \")\n",
        "!tar xvf Automating-Intention-Mining-parsed-data.tar.gz\n",
        "print(\"Extracting files... done\")\n",
        " \n",
        "# Load data\n",
        "projects = ['DECA', 'bootstrap', 'docker', 'tensorflow', 'vscode']\n",
        "categories = [\n",
        "  'aspect evaluation', 'feature request', 'information giving',\n",
        "  'information seeking', 'problem discovery', 'solution proposal', 'others'\n",
        "]\n",
        " \n",
        "_parsed_cat_proj = {}\n",
        "for c in categories:\n",
        "  _parsed_cat_proj[c] = {}\n",
        "  for p in projects:\n",
        "    with open(os.path.join(parsed_folder, p, c + \".json\"), 'r', encoding='latin-1') \\\n",
        "      as f:\n",
        "      j = json.load(f)\n",
        "      assert c == j[\"docId\"]\n",
        "      _parsed_cat_proj[c][p] = j[\"sentences\"]\n",
        "      # for s in j[\"sentences\"]:\n",
        "      #   _parsed_cat_proj[c][p].append(Sentence(s, \"{lemma}/{pos}\"))\n",
        " \n",
        "def GetAllText(\n",
        "  word=\"word\", show_pos=False, remove_punctuation=False, remove_stopwords=False,\n",
        "  get_ancestors=True, projects_to_exclude=None\n",
        "):\n",
        " \n",
        "  if word == \"word\":\n",
        "    fmt = \"{originalText}\"\n",
        "  elif word == \"lemma\":\n",
        "    fmt = \"{lemma}\"\n",
        "  else:\n",
        "    raise Exception(\"Value (\\\"{}\\\") for @word not recognized.\")\n",
        "  if show_pos:\n",
        "    fmt += \"/{pos}\"\n",
        " \n",
        "  if remove_stopwords:\n",
        "    constructor1 = lambda *args: Sentence(*args).withoutStopWords()\n",
        "  else:\n",
        "    constructor1 = lambda *args: Sentence(*args)\n",
        " \n",
        "  if remove_punctuation:\n",
        "    constructor2 = lambda *args: constructor1(*args).withoutPunctuation()\n",
        "  else:\n",
        "    constructor2 = constructor1\n",
        " \n",
        "  if projects_to_exclude is None:\n",
        "    projects_to_exclude = []\n",
        "  elif isinstance(projects_to_exclude, str):\n",
        "    projects_to_exclude = [projects_to_exclude]\n",
        " \n",
        "  projects_to_exclude = [p.lower() for p in projects_to_exclude]\n",
        " \n",
        "  return \\\n",
        "  [\n",
        "    constructor2(sentence, fmt, get_ancestors)\n",
        "    for category_name, projects in _parsed_cat_proj.items()\n",
        "    for project_name, project_text in projects.items()\n",
        "    for sentence in project_text\n",
        "    if project_name.lower() not in projects_to_exclude\n",
        "  ]\n",
        " \n",
        " \n",
        "def GetTextByCategories(\n",
        "  word=\"word\", show_pos=False, remove_punctuation=False, remove_stopwords=False,\n",
        "  get_ancestors=True, projects_to_exclude=None\n",
        "):\n",
        " \n",
        "  if word == \"word\":\n",
        "    fmt = \"{originalText}\"\n",
        "  elif word == \"lemma\":\n",
        "    fmt = \"{lemma}\"\n",
        "  else:\n",
        "    raise Exception(\"Value (\\\"{}\\\") for @word not recognized.\")\n",
        "  if show_pos:\n",
        "    fmt += \"/{pos}\"\n",
        " \n",
        "  if remove_stopwords:\n",
        "    constructor1 = lambda *args: Sentence(*args).withoutStopWords()\n",
        "  else:\n",
        "    constructor1 = lambda *args: Sentence(*args)\n",
        " \n",
        "  if remove_punctuation:\n",
        "    constructor2 = lambda *args: constructor1(*args).withoutPunctuation()\n",
        "  else:\n",
        "    constructor2 = constructor1\n",
        " \n",
        "  if projects_to_exclude is None:\n",
        "    projects_to_exclude = []\n",
        "  elif isinstance(projects_to_exclude, str):\n",
        "    projects_to_exclude = [projects_to_exclude]\n",
        " \n",
        "  projects_to_exclude = [p.lower() for p in projects_to_exclude]\n",
        " \n",
        "  return \\\n",
        "  {\n",
        "    category_name:\n",
        "    [\n",
        "      constructor2(sentence, fmt, get_ancestors)\n",
        "      for project_name, project_text in projects.items()\n",
        "      for sentence in project_text\n",
        "      if project_name.lower() not in projects_to_exclude\n",
        "    ]\n",
        "    for category_name, projects in _parsed_cat_proj.items()\n",
        "  }\n",
        " \n",
        " \n",
        "print(\n",
        "  '\\n\\n=======================================\\n'\n",
        "  + 'Use GetAllText() to get all text as a list.\\n'\n",
        "  + 'Use GetTextByCategories() to get a dictionary with category names as\\n'\n",
        "  + '  keys and lists of sentences belonging to that category as values.\\n'\n",
        "  + '=======================================\\n'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Downloading Automating-Intention-Mining-parsed-data.tar.gz: file already exists. Skipping download.\n",
            "done\n",
            "Extracting files... \n",
            "parsed/\n",
            "parsed/bootstrap/\n",
            "parsed/bootstrap/information seeking.json\n",
            "parsed/bootstrap/information giving.json\n",
            "parsed/bootstrap/feature request.json\n",
            "parsed/bootstrap/others.json\n",
            "parsed/bootstrap/solution proposal.json\n",
            "parsed/bootstrap/problem discovery.json\n",
            "parsed/bootstrap/aspect evaluation.json\n",
            "parsed/DECA/\n",
            "parsed/DECA/information seeking.json\n",
            "parsed/DECA/information giving.json\n",
            "parsed/DECA/feature request.json\n",
            "parsed/DECA/others.json\n",
            "parsed/DECA/solution proposal.json\n",
            "parsed/DECA/problem discovery.json\n",
            "parsed/DECA/aspect evaluation.json\n",
            "parsed/docker/\n",
            "parsed/docker/information seeking.json\n",
            "parsed/docker/information giving.json\n",
            "parsed/docker/feature request.json\n",
            "parsed/docker/others.json\n",
            "parsed/docker/solution proposal.json\n",
            "parsed/docker/problem discovery.json\n",
            "parsed/docker/aspect evaluation.json\n",
            "parsed/vscode/\n",
            "parsed/vscode/information seeking.json\n",
            "parsed/vscode/information giving.json\n",
            "parsed/vscode/feature request.json\n",
            "parsed/vscode/others.json\n",
            "parsed/vscode/solution proposal.json\n",
            "parsed/vscode/problem discovery.json\n",
            "parsed/vscode/aspect evaluation.json\n",
            "parsed/tensorflow/\n",
            "parsed/tensorflow/information seeking.json\n",
            "parsed/tensorflow/information giving.json\n",
            "parsed/tensorflow/feature request.json\n",
            "parsed/tensorflow/others.json\n",
            "parsed/tensorflow/solution proposal.json\n",
            "parsed/tensorflow/problem discovery.json\n",
            "parsed/tensorflow/aspect evaluation.json\n",
            "Extracting files... done\n",
            "\n",
            "\n",
            "=======================================\n",
            "Use GetAllText() to get all text as a list.\n",
            "Use GetTextByCategories() to get a dictionary with category names as\n",
            "  keys and lists of sentences belonging to that category as values.\n",
            "=======================================\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdTcnVIk0KHf"
      },
      "source": [
        "#@title StandfordNLP { display-mode: \"form\" }\n",
        "force_reparse = False #@param {type:\"boolean\"}\n",
        "\n",
        "if force_reparse:\n",
        "  # Install stanfordnlp (Needed for CoreNLPParser to work)\n",
        "  !pip install stanfordnlp\n",
        "  import os\n",
        "  import subprocess\n",
        "  import google.colab.files\n",
        "  \n",
        "  #   Download the Stanford CoreNLP Java library and unzip it to a ./corenlp folder\n",
        "  if not os.path.exists('./corenlp/'):\n",
        "    !echo \"Downloading CoreNLP...\"\n",
        "    !wget \"http://nlp.stanford.edu/software/stanford-corenlp-full-2018-10-05.zip\" -O corenlp.zip\n",
        "    !unzip \"corenlp.zip\"\n",
        "    !mv ./stanford-corenlp* ./corenlp\n",
        "  \n",
        "  \n",
        "  base_folder = \"data/\"\n",
        "  out_folder = \"parsed/\"\n",
        "  \n",
        "  try:\n",
        "    os.mkdir(out_folder)\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "  for (path, _, files) in os.walk(base_folder):\n",
        "    for category in files:\n",
        "      dirout = path.replace(base, out_folder)\n",
        "      try:\n",
        "        os.mkdir(dirout)\n",
        "      except:\n",
        "        pass\n",
        "      subprocess.call([\n",
        "        \"java\", \"-Xmx4G\",\n",
        "        \"-cp\", \"./corenlp/*\", \"edu.stanford.nlp.pipeline.StanfordCoreNLP\",\n",
        "        \"-annotators\", \"tokenize,ssplit,pos,lemma,parse\",\n",
        "        \"-threads\", \"5\",\n",
        "        \"-outputFormat\", \"json\", \n",
        "        \"-outputDirectory\", dirout,\n",
        "        \"-ssplit.eolonly\", \n",
        "        \"-isOneDocument\",\n",
        "        \"-file\", os.path.join(path, category)\n",
        "      ])\n",
        "  \n",
        "  !tar cvzf aim_parsed.tar.gz parsed\n",
        "  google.colab.files.download('aim_parsed.tar.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0lA8-RGIljf"
      },
      "source": [
        "# Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lsq8gEsUUfcP",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "a46aaf67-af5e-4b2b-e4e5-55e38c055ce3"
      },
      "source": [
        "# @title Preprocess(dataset__or__list_of_tuples)\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.stem.wordnet import WordNetLemmatizer as lem\n",
        "stop_words = set(stopwords.words('english')) \n",
        "stop_words.add('would')\n",
        "\n",
        "def Preprocess(dataset):\n",
        "    for ix, (sent, label) in enumerate(dataset):\n",
        "        sent = word_tokenize(sent)\n",
        "        sent = [w.lower() for w in sent if re.fullmatch('[a-zA-Z.][a-zA-Z.]+', w)]\n",
        "        lemmatizer = lem()\n",
        "        sent = [lemmatizer.lemmatize(w) for w in sent]\n",
        "        # Removing stop words seems to hurt the model's performance.\n",
        "        # sent = [w for w in sent if w not in stop_words]\n",
        "        dataset[ix] = (sent, label)\n",
        "\n",
        "# def preprocess(data):\n",
        "#   filtered = []\n",
        "#   for i in data:\n",
        "#     sent = re.sub(r'[^a-zA-Z ]+', '', i).lower()\n",
        "#     sent = word_tokenize(sent)\n",
        "#     tok_sent = []\n",
        "#     for w in sent:\n",
        "#       if not w in stop_words:\n",
        "#         lemmatized = lem().lemmatize(w)\n",
        "#         tok_sent.append(lemmatized)\n",
        "#     filtered.append(tok_sent)\n",
        "#   return filtered"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSUlI3E3ZIOv",
        "cellView": "form"
      },
      "source": [
        "# @title word2tensor(dataset__or__list_of_tuples, text_vocab, label_vocab, pad_length)\n",
        "\n",
        "def word2tensor(dataset, text_vocab, label_vocab, pad_length):\n",
        "    # Transforms text and labels to numerical indices using vocabulary built\n",
        "    # using this dataset.\n",
        "    #\n",
        "    #   pad_length      Length to pad to (e.g., pad_length = 100, but\n",
        "    #                   sentence is 75 characters, then 25 <pad> characters\n",
        "    #                   will be added.\n",
        "    #   dataset         Dataset to which to apply this. Iterating dataset\n",
        "    #                   should return a (text, label) tuple. Default: self \n",
        "    #                   (if dataset=None, use self).\n",
        "    #\n",
        "    # Warning: assumes that text has already been preprocessed and split!\n",
        "\n",
        "    out = []\n",
        "\n",
        "    # Text to numerical indices (tensors)\n",
        "    for ix in range(len(dataset)):\n",
        "        sentence = [text_vocab.stoi[word] for word in dataset[ix][0]]\n",
        "        if label_vocab is not None:\n",
        "            label = label_vocab.stoi[dataset[ix][1]]\n",
        "        else:\n",
        "            label = []\n",
        "\n",
        "        if pad_length is not None and len(sentence) > pad_length:\n",
        "            warnings.warn(\n",
        "                'The following sentence has {} characters which is longer '\\\n",
        "                'than your padding length ({}).\\nSentence = \"{}\"'\\\n",
        "                .format(len(sentence), pad_length, sentence)\n",
        "            )\n",
        "        elif pad_length is not None:\n",
        "            sentence = sentence + [text_vocab.stoi['<pad>']]*(pad_length-len(sentence))\n",
        "\n",
        "        out.append((torch.tensor(sentence), torch.tensor(label)))\n",
        "    \n",
        "    return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L18ds5m1YeMy"
      },
      "source": [
        "# @title Predict(model, text) {display-mode: \"form\"}\n",
        "\n",
        "def Predict(model, vocab, text):\n",
        "    # Not learning\n",
        "    model.eval()\n",
        "    # For strings\n",
        "    if not isinstance(text, list):\n",
        "        text = [text]\n",
        "    # Create \"dataset\"\n",
        "    text_labels = [(sentence, '') for sentence in text]\n",
        "    Preprocess(text_labels)\n",
        "    # Word 2 tensor + padding\n",
        "    text_labels = word2tensor(text_labels, vocab, None, saved['params']['_padded_string_length'])\n",
        "    # (text,label)->[text,text,...]\n",
        "    text = torch.stack([sentence for sentence, label in text_labels], dim=0)\n",
        "    # CUDA?\n",
        "    text = text.to(next(model.parameters()).device)\n",
        "    # Prediction\n",
        "    return torch.argmax(model(text).cpu(), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A63W_X01yHSl"
      },
      "source": [
        "# @title GetWordsByTfidf(dict_corpus) {display-mode: \"form\"}\n",
        "\n",
        "def GetWordsByTfidf(dict_corpus):\n",
        "# dict_corpus:  list or dictionary of documents.\n",
        "#               If a dictionary is provided, the key names are used as column\n",
        "#               names in the words_by_tfidf dataframe.\n",
        "  from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "\n",
        "  # corpus\n",
        "  if isinstance(dict_corpus, dict):\n",
        "    corpus = list(dict_corpus.values())\n",
        "    category_names = dict_corpus.keys()\n",
        "  else:\n",
        "    corpus = dict_corpus\n",
        "    category_names = None\n",
        "  \n",
        "  # create vectorizer\n",
        "  #   Note: Lemmatizer needs original case, so don't lowercase. Let\n",
        "  #         the tokenizer/lemmatizer handle that.\n",
        "  tfidf_vectorizer = TfidfVectorizer(\n",
        "    use_idf=True, lowercase=False, preprocessor=lambda x: x, tokenizer=lambda x: x \n",
        "  )\n",
        "    \n",
        "  # just send in all your docs here\n",
        "  tfidf_vectorizer_vectors = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "  words = tfidf_vectorizer.get_feature_names()\n",
        "  words_by_tfidf = []\n",
        "  for tf in tfidf_vectorizer_vectors:\n",
        "    # np.sort() and np.argsort() always sort by ascending order, so sort negative\n",
        "    # scores to get descending order\n",
        "    #   Words in current category sorted by tfidf score\n",
        "    cat_by_tfidf = []\n",
        "    for ix in np.argsort(-tf.toarray()).flatten():\n",
        "      cat_by_tfidf.append(Token(words[ix].default_format, {**words[ix].properties, \"score\": tf[0,ix]}))\n",
        "    words_by_tfidf.append(cat_by_tfidf)\n",
        "\n",
        "  words_by_tfidf = pd.DataFrame(data=words_by_tfidf, index=category_names).transpose()\n",
        "\n",
        "  return words_by_tfidf, tfidf_vectorizer_vectors, words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmibTLAG_O-V"
      },
      "source": [
        "# @title GetWordsByZInOut(dict_corpus) {display-mode: \"form\"}\n",
        "\n",
        "def GetWordsByZInOut(dict_corpus):\n",
        "# dict_corpus:  list or dictionary of documents.\n",
        "#               If a dictionary is provided, the key names are used as column\n",
        "#               names in the words_by_tfidf dataframe.\n",
        "  from sklearn.feature_extraction.text import CountVectorizer\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "\n",
        "  # corpus\n",
        "  if isinstance(dict_corpus, dict):\n",
        "    corpus = list(dict_corpus.values())\n",
        "    category_names = dict_corpus.keys()\n",
        "  else:\n",
        "    corpus = dict_corpus\n",
        "    category_names = None\n",
        "  \n",
        "  # create vectorizer\n",
        "  count_vectorizer = CountVectorizer(\n",
        "    lowercase=False, preprocessor=lambda x: x, tokenizer=lambda x: x\n",
        "  )\n",
        "    \n",
        "  # just send in all your docs here\n",
        "  count_vectorizer_vectors = count_vectorizer.fit_transform(corpus)\n",
        "\n",
        "  # Use counts to calculate z-scored in-out\n",
        "  #   Counts of the times the word appeared in a sentence of that category\n",
        "  count_in = pd.DataFrame(\n",
        "    data=count_vectorizer_vectors.toarray(),\n",
        "    index=category_names,\n",
        "    columns=count_vectorizer.get_feature_names()\n",
        "  ).transpose()\n",
        "  #   zscores for in-category occurrences\n",
        "  z_in = (count_in - count_in.mean(axis=0)) / count_in.std(axis=0)\n",
        "  #   Counts of the times the word appeared in the other categories\n",
        "  count_out = -count_in.subtract(count_in.sum(axis=1), axis='rows')\n",
        "  #   zscores for out-category occurrences\n",
        "  z_out = (count_out - count_out.mean(axis=0)) / count_out.std(axis=0)\n",
        "  #   z-scored in-out: final score representing words that are frequent in this\n",
        "  #     category, but not in others\n",
        "  z_inout = z_in - z_out\n",
        "\n",
        "  words = count_vectorizer.get_feature_names()\n",
        "\n",
        "  # We originally wanted to divide, but given the nature of z-scores, that\n",
        "  # favored words which appeared an average amount of times (denom near 0).\n",
        "  # This measure, instead, favors words which appear frequently inside the\n",
        "  # category and infrequently outside of the category.\n",
        "\n",
        "  words_by_zinout = []\n",
        "  for col in range(z_inout.shape[1]):\n",
        "    sorted_desc_index = np.argsort(-z_inout.iloc[:, col].to_numpy())\n",
        "    cat_by_zinout = []\n",
        "    for ix in sorted_desc_index:\n",
        "      w = words[ix]\n",
        "      cat_by_zinout.append(Token(w.default_format, {**w.properties, \"score\": z_inout.iloc[ix, col]}))\n",
        "    words_by_zinout.append(cat_by_zinout)\n",
        "\n",
        "  words_by_zinout = pd.DataFrame(data=words_by_zinout, index=category_names).transpose()\n",
        "\n",
        "  return words_by_zinout, z_inout, count_vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uS8MpAQQ_PXF"
      },
      "source": [
        "# @title CalculateOverlap() {display-mode: \"form\"}\n",
        "\n",
        "def CalculateOverlap(df_sorted_words, N, ignore_pos=False):\n",
        "  # df_sorted_words:  DataFrame containing words sorted by some score. The top \n",
        "  #                   N words are compared across columns and a matrix with\n",
        "  #                   the overlap is returned\n",
        "  import pandas as pd\n",
        "  import numpy as np\n",
        "\n",
        "  df_sorted_words = df_sorted_words[:N]\n",
        "  if ignore_pos:\n",
        "    df_sorted_words = df_sorted_words.applymap(lambda e: e.to_string(\"{lemma}\"))\n",
        "  else:\n",
        "    df_sorted_words = df_sorted_words.applymap(lambda e: e.to_string(\"{lemma}/{pos}\"))\n",
        "\n",
        "  matrix = np.zeros(2*(len(df_sorted_words.columns),)) # 2*(7,) = (7,7)\n",
        "\n",
        "  for ix in range(matrix.shape[0]):\n",
        "    matrix[ix,ix] = 1\n",
        "    for jx in range(1+ix, matrix.shape[1]):\n",
        "      matrix[ix, jx] = matrix[jx, ix] = len(\n",
        "        set(df_sorted_words.iloc[:, ix]) &  set(df_sorted_words.iloc[:, jx])\n",
        "      ) / N\n",
        "  \n",
        "  return pd.DataFrame(matrix, df_sorted_words.columns, df_sorted_words.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjJ0yXVPR492"
      },
      "source": [
        "# @title PennToSimple() {display-mode: \"form\"}\n",
        "\n",
        "# _PennSimpleDict = \\\n",
        "# {\n",
        "#   'CC': 'other',\n",
        "#   'CD': 'other',\n",
        "#   'DT': 'determiners',\n",
        "#   'EX': 'other',\n",
        "#   'FW': 'other',\n",
        "#   'IN': 'other',\n",
        "#   'JJ': 'adjectives',\n",
        "#   'JJR': 'adjectives',\n",
        "#   'JJS': 'adjectives',\n",
        "#   'LS': 'other',\n",
        "#   'MD': 'verbs',  #will, would, can, could, etc.\n",
        "#   'NN': 'nouns',\n",
        "#   'NNS': 'nouns',\n",
        "#   'NNP': 'nouns',\n",
        "#   'NNPS': 'nouns',\n",
        "#   'PDT': 'determiners',\n",
        "#   'POS': 'other',\n",
        "#   'PRP': 'pronouns',\n",
        "#   'PRP$': 'other',\n",
        "#   'RB': 'adverbs',\n",
        "#   'RBR': 'adverbs',\n",
        "#   'RBS': 'adverbs',\n",
        "#   'RP': 'other',\n",
        "#   'SYM': 'other',\n",
        "#   'TO': 'other',\n",
        "#   'UH': 'other',\n",
        "#   'VB': 'verbs',\n",
        "#   'VBD': 'verbs',\n",
        "#   'VBG': 'verbs',\n",
        "#   'VBN': 'verbs',\n",
        "#   'VBP': 'verbs',\n",
        "#   'VBZ': 'verbs',\n",
        "#   'WDT': 'determiners',\n",
        "#   'WP': 'other',\n",
        "#   'WP$': 'other',\n",
        "#   'WRB': 'adverbs'\n",
        "# }\n",
        "\n",
        "_PennSimpleDict = \\\n",
        "{\n",
        "  'JJ': 'J',\n",
        "  'JJS': 'J',\n",
        "  'JJR': 'J',\n",
        "  'NN': 'N',\n",
        "  'NNS': 'N',\n",
        "  'NNP': 'N',\n",
        "  'NNPS': 'N',\n",
        "  'RB': 'R',\n",
        "  'RBR': 'R',\n",
        "  'RBS': 'R',\n",
        "  'VB': 'V',\n",
        "  'VBD': 'V',\n",
        "  'VBG': 'V',\n",
        "  'VBN': 'V',\n",
        "  'VBP': 'V',\n",
        "  'VBZ': 'V',\n",
        "  'MD': 'V',  #verb: will, would, can, could, etc.\n",
        "}\n",
        "\n",
        "def PennToSimple(tag):\n",
        "  # Penn POS tagging to simple, intuitive tagging\n",
        "  # return _PennSimpleDict[tag]\n",
        "  return _PennSimpleDict.get(tag, tag)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3JdB3-3kyKy"
      },
      "source": [
        "# @title WordByScore2TagByScore() {display-mode: \"form\"}\n",
        "\n",
        "def _AggregateTagScores(series_tags_scores):\n",
        "  import numpy as np\n",
        "\n",
        "  tag_set = set(series_tags_scores.apply(lambda e: e[1]))\n",
        "  total_tag_score = {\n",
        "      cat: [] for cat in tag_set\n",
        "  }\n",
        "  for score, tag in series_tags_scores:\n",
        "    total_tag_score[tag].append(score)\n",
        "  total_tag_score = [(np.sum(scores), tag) for tag, scores in total_tag_score.items()]\n",
        "  # total_tag_score = [(np.mean(scores), tag) for tag, scores in total_tag_score.items()]\n",
        "  return pd.Series(data=total_tag_score, index=tag_set)\n",
        "\n",
        "def WordByScore2TagByScore(words_sorted_by_score, pos_key=\"pos\"):\n",
        "  tag_by_score = words_sorted_by_score.applymap(lambda e: (e[\"score\"], PennToSimple(e[pos_key])))\n",
        "  tag_by_score = tag_by_score.apply(_AggregateTagScores)\n",
        "  tag_by_score.reset_index(drop=True, inplace=True)\n",
        "  return tag_by_score.apply(\n",
        "    lambda S: pd.Series(data=S.sort_values(ascending=False).to_list())\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqeZ-el2LFJD"
      },
      "source": [
        "# @title DisplayTopN(), DisplayOverlapMatrix() {display-mode: \"form\"}\n",
        "\n",
        "def DisplayTopN(df_sorted_words, N, display_score=False):\n",
        "  df_sorted_words = df_sorted_words[:N]\n",
        "  if display_score:\n",
        "    df_sorted_words = df_sorted_words.applymap(\n",
        "      lambda e: e.to_string(lambda x: old_format() + \"/{score:.2f}\")\n",
        "    )\n",
        "  display(df_sorted_words)\n",
        "  \n",
        "def DisplayOverlapMatrix(matrix, upper_triangle=True, remove_pos=False):\n",
        "  matrix = matrix.applymap(lambda e: \"{:.2f}\".format(float(e)))\n",
        "  if upper_triangle:\n",
        "    for (x,y) in zip(*np.where(np.invert(np.triu(np.full_like(matrix, True, dtype=bool))))):\n",
        "      matrix.iloc[x,y] = ' '\n",
        "  display(matrix)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LirZTkEKcMee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "09460e5c-f1c5-4dd9-c6e0-dcf8a0a3dd16"
      },
      "source": [
        "# @title POS tagging and chunking {display-mode: \"form\"}\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "def pos_tag(sentence):\n",
        "  return nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "\n",
        "def chunk_sentences(sentence):\n",
        "  grammar = ('''\n",
        "    NP: {<DT>?<JJ>*<NN>} # NP\n",
        "    ''')\n",
        "  tagged = pos_tag(sentence)\n",
        "  chunkParser = nltk.RegexpParser(grammar)\n",
        "  tree = chunkParser.parse(tagged)\n",
        "  return tree"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnbkU8zwIUsX"
      },
      "source": [
        "# Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5H9Nq1bK-Tl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "outputId": "a38bb8e8-30c0-4e82-f251-66def812fa9c"
      },
      "source": [
        "# @title Augmented sentences {display-mode: \"form\"}\n",
        "from IPython.core.display import display, HTML\n",
        "import numpy as np\n",
        "\n",
        "text = GetTextByCategories(word=\"word\", show_pos=False, remove_punctuation=False, remove_stopwords=False)\n",
        "\n",
        "len(text)\n",
        "categories = list(text.keys())\n",
        "\n",
        "for ii in range(10):\n",
        "  swap_1 = swap_2 = None\n",
        "  while swap_1 is None or swap_2 is None:\n",
        "    cat_1 = categories[np.random.randint(len(text))]\n",
        "    cat_2 = categories[np.random.randint(len(text))]\n",
        "    sent_1 = text[cat_1][np.random.randint(len(text[cat_1]))]\n",
        "    sent_2 = text[cat_2][np.random.randint(len(text[cat_2]))]\n",
        "    swap_1, swap_2 = Sentence.SwapPhrases(\n",
        "      sent_1, sent_2, \"ADJP\",\n",
        "      prefix=['<span style=\"color: red\">', '<span style=\"color: blue\">'],\n",
        "      suffix=\"</span>\"\n",
        "    )\n",
        "\n",
        "  display(HTML(\"<b>O1:</b> \" + str(sent_1)))\n",
        "  display(HTML(\"<b>O2:</b> \" + str(sent_2)))\n",
        "  display(HTML(\"<b>S1:</b> \" + str(swap_1)))\n",
        "  display(HTML(\"<b>S2:</b> \" + str(swap_2)))\n",
        "  print()\n",
        "\n",
        "print(\"\\n\\n\\n\")\n",
        "\n",
        "# for ii in range(10):\n",
        "#   cat_1 = categories[np.random.randint(len(text))]\n",
        "#   cat_2 = categories[np.random.randint(len(text))]\n",
        "#   sent_1 = text[cat_1][np.random.randint(len(text[cat_1]))]\n",
        "#   sent_2 = text[cat_2][np.random.randint(len(text[cat_2]))]\n",
        "#   swap_1, swap_2 = Sentence.SwapPhrases(sent_1, sent_2, \"VP\")\n",
        "\n",
        "#   print(sent_1, sent_2)\n",
        "#   print(swap_1, swap_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> I realize it's not <span style=\"color: red\">right</span> (for one thing I'm not feeding it a feed_dict), but it should give an error and not crash the kernel.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> hmm <span style=\"color: blue\">interesting</span>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> I realize it's not <span style=\"color: blue\">interesting</span>(for one thing I'm not feeding it a feed_dict), but it should give an error and not crash the kernel.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> hmm <span style=\"color: red\">right</span> ."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> Sounds <span style=\"color: red\">good</span>.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> Once we are <span style=\"color: blue\">more able to accept external contributions</span>, improvements like these from the community are welcome!\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> Sounds <span style=\"color: blue\">more able to accept external contributions</span>.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> Once we are <span style=\"color: red\">good</span>, improvements like these from the community are welcome!\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> All we need to do is build all Qt dylibs with install_name = @rpath/pathrelative_to_lib_folder/some.dylib and make <span style=\"color: red\">sure</span> qmake adds following linker flags to all apps linking to Qt:\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> And connecting via Computer-System Configuration-Networking did eventually work but was <span style=\"color: blue\">very non</span> responsive\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> All we need to do is build all Qt dylibs with install_name = @rpath/pathrelative_to_lib_folder/some.dylib and make <span style=\"color: blue\">very non</span> qmake adds following linker flags to all apps linking to Qt:\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> And connecting via Computer-System Configuration-Networking did eventually work but was <span style=\"color: red\">sure</span> responsive\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> Unfortunately, I tried it and although I got <span style=\"color: red\">really close to doing a complete Bazel PIP build</span>, it failed when trying near the end when going through the cuDNN v5 library.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> There is a variable <span style=\"color: blue\">$custom-control-spacer-y</span> in the _variables.scss but it isn't used anywhere.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> Unfortunately, I tried it and although I got <span style=\"color: blue\">$custom-control-spacer-y</span> , it failed when trying near the end when going through the cuDNN v5 library.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> There is a variable <span style=\"color: red\">really close to doing a complete Bazel PIP build</span>in the _variables.scss but it isn't used anywhere.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> is there no other encoding we provide that can deal with cp850, <span style=\"color: red\">e.g. windows1252</span>?\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> However, when i downloaded the file myself and renamed it to \"tensorflow-0.7.0-cp34-none-linux_x86_64.whl\", then executed the command again with <span style=\"color: blue\">changed</span> filename, it worked =)\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> is there no other encoding we provide that can deal with cp850, <span style=\"color: blue\">changed</span> ?\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> However, when i downloaded the file myself and renamed it to \"tensorflow-0.7.0-cp34-none-linux_x86_64.whl\", then executed the command again with <span style=\"color: red\">e.g. windows1252</span>filename, it worked =)\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> I hope I wasn't <span style=\"color: red\">rude</span>.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> A slightly modified BUILD works <span style=\"color: blue\">fine though</span> (for GPU-only kernels):\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> I hope I wasn't <span style=\"color: blue\">fine though</span> .\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> A slightly modified BUILD works <span style=\"color: red\">rude</span>(for GPU-only kernels):\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> I think this is <span style=\"color: red\">identical to the current implementation but using cufftExecR2C() and cufftExecC2R() instead of cufftExec</span>() \n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> I am <span style=\"color: blue\">sorry it took me so long</span>.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> I think this is <span style=\"color: blue\">sorry it took me so long</span>() \n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> I am <span style=\"color: red\">identical to the current implementation but using cufftExecR2C() and cufftExecC2R() instead of cufftExec</span>.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> it is <span style=\"color: red\">worthwhile to add trigamma or polygamma from cephes</span>. \n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> I also want to have some default implementations of the baseclass to be <span style=\"color: blue\">available and invoked</span>, in case the derived class does not provide its own implementation.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> it is <span style=\"color: blue\">available and invoked</span>. \n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> I also want to have some default implementations of the baseclass to be <span style=\"color: red\">worthwhile to add trigamma or polygamma from cephes</span>, in case the derived class does not provide its own implementation.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> However, some steps are not the easiest for users who are not <span style=\"color: red\">familiar with GPU programming</span>.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> We could try a workaround where we gratuitously keep a ref on a <span style=\"color: blue\">recently created</span> device (unless you're trying to delete it) for say 1 second."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> However, some steps are not the easiest for users who are not <span style=\"color: blue\">recently created</span> .\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> We could try a workaround where we gratuitously keep a ref on a <span style=\"color: red\">familiar with GPU programming</span>device (unless you're trying to delete it) for say 1 second."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O1:</b> Maybe it is <span style=\"color: red\">related to the error I have here to #4930</span>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>O2:</b> I had a few segfaults along the way when I mismatched things, eg: if you only have one worker specified and set task_index<span style=\"color: blue\">=1</span> will SEGFAULT.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S1:</b> Maybe it is <span style=\"color: blue\">=1</span> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<b>S2:</b> I had a few segfaults along the way when I mismatched things, eg: if you only have one worker specified and set task_index<span style=\"color: red\">related to the error I have here to #4930</span>\n",
              "will SEGFAULT.\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qxsOQGn4FLg"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojthi_9ZEo2j"
      },
      "source": [
        "### With stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHkM4nc4DKdz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0f8c59b5-155c-445c-d10e-5cf937ac5633"
      },
      "source": [
        "# @title TFIDF (w/ stopwords): top-10 words for each category + overlap matrix {display-mode: \"form\"}\n",
        "# Q: What are the documents and what is the corpus?\n",
        "# A: There are a few options.\n",
        "#   One option is to consider each category as a document and the corpus as the\n",
        "# set of categories. That is to say that we combine each category's sentences\n",
        "# into a single string (document), thus obtaining 7 documents which form our\n",
        "# corpus.\n",
        "#  Another option is to ignore category boundaries. Each sentence is its own\n",
        "# document and the corpus is the set of sentencs. The TFIDF score should then\n",
        "# indicate the importance of a given word (e.g., 'the') relative to the sentence\n",
        "# rather than the category. Then, for each word which appears at least once in\n",
        "# a given category's sentences, we would obtain a score which could be something\n",
        "# like the mean of all of that words' tfidf scores (or the max). The issue with\n",
        "# this analysis is that it is unclear how to combine the scores or what they\n",
        "# mean.\n",
        "#   Finally, an option that one could consider would be to set the documents to\n",
        "# be the sentences of a category and the corpus to be only those sentences\n",
        "# belonging to that category. In that case, however, it is unclear what the\n",
        "# TFIDF represents. For example, let's say \"Thank you\" appears once in \"Solution\n",
        "# proposal.\" \"Thank\" may get a (decently) high score for that category would\n",
        "# consequently be considered (decently) meaningful. However, we know that the\n",
        "# \"other\" category has many occurrences of the word \"thank,\" meaning that it\n",
        "# isn't diagnostic of \"solution proposal\" (even though it would get a decent\n",
        "# score).\n",
        "\n",
        "# The difference between the first and second analysis is the difference between\n",
        "# calculating tfidf scores for a list of sentences of using a single document\n",
        "# comprised of those same sentences.\n",
        "\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "text_by_categories = GetTextByCategories(word=\"lemma\", show_pos=False, remove_punctuation=True, remove_stopwords=False)\n",
        "\n",
        "# (1) Documents = category; Corpus = all categories\n",
        "#   Combine all the sentences of a given category into a single document. Tfidf\n",
        "# then is just the colum corresponding to each category.\n",
        "\n",
        "# Combine categories' sentences (list of words) into a single document (list)\n",
        "documents = {}\n",
        "for cat, sentences in text_by_categories.items():\n",
        "  documents[cat] = []\n",
        "  for s in sentences:\n",
        "    documents[cat].extend(s.tokens)\n",
        "  \n",
        "words_by_tfidf_with, tfidf, _ = GetWordsByTfidf(documents)\n",
        "pd.options.display.max_rows = 100\n",
        "DisplayTopN(words_by_tfidf_with.applymap(lambda t: Token(\"{lemma}\", t.properties)), 10, False)\n",
        "\n",
        "# Overlap in top-100\n",
        "over = CalculateOverlap(words_by_tfidf_with, 100)\n",
        "DisplayOverlapMatrix(over)\n",
        "\n",
        "tag_by_tfidf = WordByScore2TagByScore(words_by_tfidf_with, pos_key=\"pos\")\n",
        "display(tag_by_tfidf.applymap(lambda e: (e[1], round(e[0], 2))))\n",
        "\n",
        "ancestor_by_tfidf = WordByScore2TagByScore(words_by_tfidf_with, pos_key=\"ancestor\")\n",
        "display(ancestor_by_tfidf.applymap(lambda e: (e[1], round(e[0], 2))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>be</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>the</td>\n",
              "      <td>for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the</td>\n",
              "      <td>to</td>\n",
              "      <td>be</td>\n",
              "      <td>the</td>\n",
              "      <td>be</td>\n",
              "      <td>to</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i</td>\n",
              "      <td>the</td>\n",
              "      <td>to</td>\n",
              "      <td>you</td>\n",
              "      <td>i</td>\n",
              "      <td>be</td>\n",
              "      <td>you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>to</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>to</td>\n",
              "      <td>to</td>\n",
              "      <td>a</td>\n",
              "      <td>i</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>a</td>\n",
              "      <td>would</td>\n",
              "      <td>i</td>\n",
              "      <td>a</td>\n",
              "      <td>a</td>\n",
              "      <td>you</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>it</td>\n",
              "      <td>it</td>\n",
              "      <td>and</td>\n",
              "      <td>do</td>\n",
              "      <td>not</td>\n",
              "      <td>i</td>\n",
              "      <td>the</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>not</td>\n",
              "      <td>i</td>\n",
              "      <td>in</td>\n",
              "      <td>this</td>\n",
              "      <td>and</td>\n",
              "      <td>and</td>\n",
              "      <td>thank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>that</td>\n",
              "      <td>for</td>\n",
              "      <td>of</td>\n",
              "      <td>i</td>\n",
              "      <td>_</td>\n",
              "      <td>for</td>\n",
              "      <td>this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>of</td>\n",
              "      <td>that</td>\n",
              "      <td>have</td>\n",
              "      <td>there</td>\n",
              "      <td>it</td>\n",
              "      <td>this</td>\n",
              "      <td>to</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>think</td>\n",
              "      <td>and</td>\n",
              "      <td>that</td>\n",
              "      <td>can</td>\n",
              "      <td>error</td>\n",
              "      <td>_</td>\n",
              "      <td>it</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal  others\n",
              "0                be              be  ...               the     for\n",
              "1               the              to  ...                to  thanks\n",
              "2                 i             the  ...                be     you\n",
              "3                to               a  ...                 a       i\n",
              "4                 a           would  ...               you      be\n",
              "5                it              it  ...                 i     the\n",
              "6               not               i  ...               and   thank\n",
              "7              that             for  ...               for    this\n",
              "8                of            that  ...              this      to\n",
              "9             think             and  ...                 _      it\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aspect evaluation</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.72</td>\n",
              "      <td>0.67</td>\n",
              "      <td>0.57</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature request</th>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.58</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information giving</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.74</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information seeking</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>problem discovery</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>solution proposal</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    aspect evaluation feature request  ... solution proposal others\n",
              "aspect evaluation                1.00            0.73  ...              0.66   0.42\n",
              "feature request                                  1.00  ...              0.64   0.42\n",
              "information giving                                     ...              0.70   0.42\n",
              "information seeking                                    ...              0.69   0.45\n",
              "problem discovery                                      ...              0.66   0.39\n",
              "solution proposal                                      ...              1.00   0.43\n",
              "others                                                 ...                     1.00\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(N, 2.61)</td>\n",
              "      <td>(N, 3.02)</td>\n",
              "      <td>(N, 3.65)</td>\n",
              "      <td>(N, 2.8)</td>\n",
              "      <td>(N, 3.7)</td>\n",
              "      <td>(N, 3.56)</td>\n",
              "      <td>(N, 2.1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(V, 2.26)</td>\n",
              "      <td>(V, 2.5)</td>\n",
              "      <td>(V, 2.27)</td>\n",
              "      <td>(V, 2.5)</td>\n",
              "      <td>(V, 2.13)</td>\n",
              "      <td>(V, 2.39)</td>\n",
              "      <td>(V, 1.78)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(J, 1.12)</td>\n",
              "      <td>(J, 1.07)</td>\n",
              "      <td>(IN, 1.23)</td>\n",
              "      <td>(DT, 0.95)</td>\n",
              "      <td>(IN, 1.0)</td>\n",
              "      <td>(IN, 1.03)</td>\n",
              "      <td>(J, 0.84)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(IN, 1.06)</td>\n",
              "      <td>(IN, 1.05)</td>\n",
              "      <td>(DT, 1.01)</td>\n",
              "      <td>(IN, 0.93)</td>\n",
              "      <td>(DT, 0.94)</td>\n",
              "      <td>(DT, 1.03)</td>\n",
              "      <td>(IN, 0.83)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(R, 0.89)</td>\n",
              "      <td>(DT, 0.85)</td>\n",
              "      <td>(J, 0.9)</td>\n",
              "      <td>(PRP, 0.63)</td>\n",
              "      <td>(J, 0.79)</td>\n",
              "      <td>(J, 0.87)</td>\n",
              "      <td>(PRP, 0.75)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(DT, 0.85)</td>\n",
              "      <td>(R, 0.57)</td>\n",
              "      <td>(R, 0.7)</td>\n",
              "      <td>(J, 0.6)</td>\n",
              "      <td>(R, 0.68)</td>\n",
              "      <td>(R, 0.61)</td>\n",
              "      <td>(DT, 0.64)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(PRP, 0.65)</td>\n",
              "      <td>(PRP, 0.45)</td>\n",
              "      <td>(PRP, 0.46)</td>\n",
              "      <td>(R, 0.38)</td>\n",
              "      <td>(PRP, 0.53)</td>\n",
              "      <td>(PRP, 0.6)</td>\n",
              "      <td>(R, 0.57)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(CC, 0.29)</td>\n",
              "      <td>(TO, 0.41)</td>\n",
              "      <td>(CC, 0.28)</td>\n",
              "      <td>(TO, 0.29)</td>\n",
              "      <td>(CD, 0.43)</td>\n",
              "      <td>(TO, 0.44)</td>\n",
              "      <td>(TO, 0.16)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(TO, 0.26)</td>\n",
              "      <td>(CC, 0.23)</td>\n",
              "      <td>(TO, 0.28)</td>\n",
              "      <td>(CD, 0.2)</td>\n",
              "      <td>(CC, 0.29)</td>\n",
              "      <td>(CC, 0.27)</td>\n",
              "      <td>(CC, 0.12)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(PRP$, 0.11)</td>\n",
              "      <td>(CD, 0.16)</td>\n",
              "      <td>(CD, 0.28)</td>\n",
              "      <td>(WRB, 0.19)</td>\n",
              "      <td>(TO, 0.21)</td>\n",
              "      <td>(CD, 0.27)</td>\n",
              "      <td>(PRP$, 0.09)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(CD, 0.09)</td>\n",
              "      <td>(PRP$, 0.12)</td>\n",
              "      <td>(PRP$, 0.16)</td>\n",
              "      <td>(CC, 0.18)</td>\n",
              "      <td>(WRB, 0.11)</td>\n",
              "      <td>(PRP$, 0.1)</td>\n",
              "      <td>(UH, 0.07)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(WRB, 0.03)</td>\n",
              "      <td>(WDT, 0.04)</td>\n",
              "      <td>(WRB, 0.05)</td>\n",
              "      <td>(EX, 0.14)</td>\n",
              "      <td>(PRP$, 0.07)</td>\n",
              "      <td>(RP, 0.04)</td>\n",
              "      <td>(RP, 0.05)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(WDT, 0.03)</td>\n",
              "      <td>(WRB, 0.03)</td>\n",
              "      <td>(EX, 0.05)</td>\n",
              "      <td>(WP, 0.13)</td>\n",
              "      <td>(EX, 0.04)</td>\n",
              "      <td>(WRB, 0.04)</td>\n",
              "      <td>(CD, 0.03)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(RP, 0.03)</td>\n",
              "      <td>(RP, 0.02)</td>\n",
              "      <td>(RP, 0.04)</td>\n",
              "      <td>(PRP$, 0.06)</td>\n",
              "      <td>(WDT, 0.03)</td>\n",
              "      <td>(WDT, 0.03)</td>\n",
              "      <td>(WP, 0.02)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(EX, 0.02)</td>\n",
              "      <td>(EX, 0.02)</td>\n",
              "      <td>(WDT, 0.04)</td>\n",
              "      <td>(RP, 0.03)</td>\n",
              "      <td>(RP, 0.03)</td>\n",
              "      <td>(FW, 0.02)</td>\n",
              "      <td>(WRB, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(WP, 0.02)</td>\n",
              "      <td>(WP, 0.02)</td>\n",
              "      <td>(FW, 0.02)</td>\n",
              "      <td>(WDT, 0.02)</td>\n",
              "      <td>(FW, 0.02)</td>\n",
              "      <td>(EX, 0.02)</td>\n",
              "      <td>(SYM, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(FW, 0.02)</td>\n",
              "      <td>(FW, 0.01)</td>\n",
              "      <td>(WP, 0.02)</td>\n",
              "      <td>(FW, 0.01)</td>\n",
              "      <td>(POS, 0.01)</td>\n",
              "      <td>(WP, 0.02)</td>\n",
              "      <td>(POS, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(POS, 0.01)</td>\n",
              "      <td>(POS, 0.01)</td>\n",
              "      <td>(POS, 0.02)</td>\n",
              "      <td>(UH, 0.01)</td>\n",
              "      <td>(UH, 0.01)</td>\n",
              "      <td>(SYM, 0.01)</td>\n",
              "      <td>(EX, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(UH, 0.0)</td>\n",
              "      <td>(SYM, 0.01)</td>\n",
              "      <td>(UH, 0.01)</td>\n",
              "      <td>(POS, 0.01)</td>\n",
              "      <td>(SYM, 0.01)</td>\n",
              "      <td>(POS, 0.01)</td>\n",
              "      <td>(WDT, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(SYM, 0.0)</td>\n",
              "      <td>(UH, 0.01)</td>\n",
              "      <td>(SYM, 0.0)</td>\n",
              "      <td>(SYM, 0.01)</td>\n",
              "      <td>(WP, 0.0)</td>\n",
              "      <td>(UH, 0.01)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(FW, 0.0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal        others\n",
              "0          (N, 2.61)       (N, 3.02)  ...         (N, 3.56)      (N, 2.1)\n",
              "1          (V, 2.26)        (V, 2.5)  ...         (V, 2.39)     (V, 1.78)\n",
              "2          (J, 1.12)       (J, 1.07)  ...        (IN, 1.03)     (J, 0.84)\n",
              "3         (IN, 1.06)      (IN, 1.05)  ...        (DT, 1.03)    (IN, 0.83)\n",
              "4          (R, 0.89)      (DT, 0.85)  ...         (J, 0.87)   (PRP, 0.75)\n",
              "5         (DT, 0.85)       (R, 0.57)  ...         (R, 0.61)    (DT, 0.64)\n",
              "6        (PRP, 0.65)     (PRP, 0.45)  ...        (PRP, 0.6)     (R, 0.57)\n",
              "7         (CC, 0.29)      (TO, 0.41)  ...        (TO, 0.44)    (TO, 0.16)\n",
              "8         (TO, 0.26)      (CC, 0.23)  ...        (CC, 0.27)    (CC, 0.12)\n",
              "9       (PRP$, 0.11)      (CD, 0.16)  ...        (CD, 0.27)  (PRP$, 0.09)\n",
              "10        (CD, 0.09)    (PRP$, 0.12)  ...       (PRP$, 0.1)    (UH, 0.07)\n",
              "11       (WRB, 0.03)     (WDT, 0.04)  ...        (RP, 0.04)    (RP, 0.05)\n",
              "12       (WDT, 0.03)     (WRB, 0.03)  ...       (WRB, 0.04)    (CD, 0.03)\n",
              "13        (RP, 0.03)      (RP, 0.02)  ...       (WDT, 0.03)    (WP, 0.02)\n",
              "14        (EX, 0.02)      (EX, 0.02)  ...        (FW, 0.02)   (WRB, 0.01)\n",
              "15        (WP, 0.02)      (WP, 0.02)  ...        (EX, 0.02)   (SYM, 0.01)\n",
              "16        (FW, 0.02)      (FW, 0.01)  ...        (WP, 0.02)    (POS, 0.0)\n",
              "17       (POS, 0.01)     (POS, 0.01)  ...       (SYM, 0.01)     (EX, 0.0)\n",
              "18         (UH, 0.0)     (SYM, 0.01)  ...       (POS, 0.01)    (WDT, 0.0)\n",
              "19        (SYM, 0.0)      (UH, 0.01)  ...        (UH, 0.01)     (LS, 0.0)\n",
              "20         (LS, 0.0)       (LS, 0.0)  ...         (LS, 0.0)     (FW, 0.0)\n",
              "\n",
              "[21 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(NP, 5.03)</td>\n",
              "      <td>(NP, 5.36)</td>\n",
              "      <td>(NP, 6.45)</td>\n",
              "      <td>(NP, 5.26)</td>\n",
              "      <td>(NP, 6.42)</td>\n",
              "      <td>(NP, 6.44)</td>\n",
              "      <td>(NP, 3.92)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(VP, 2.75)</td>\n",
              "      <td>(VP, 2.95)</td>\n",
              "      <td>(VP, 2.62)</td>\n",
              "      <td>(VP, 2.77)</td>\n",
              "      <td>(VP, 2.51)</td>\n",
              "      <td>(VP, 2.77)</td>\n",
              "      <td>(VP, 1.94)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(ADJP, 0.87)</td>\n",
              "      <td>(PP, 0.73)</td>\n",
              "      <td>(PP, 0.98)</td>\n",
              "      <td>(PP, 0.7)</td>\n",
              "      <td>(PP, 0.79)</td>\n",
              "      <td>(PP, 0.87)</td>\n",
              "      <td>(ADJP, 0.8)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(PP, 0.74)</td>\n",
              "      <td>(ADJP, 0.7)</td>\n",
              "      <td>(ADVP, 0.46)</td>\n",
              "      <td>(ADJP, 0.39)</td>\n",
              "      <td>(ADVP, 0.41)</td>\n",
              "      <td>(ADJP, 0.48)</td>\n",
              "      <td>(PP, 0.69)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(ADVP, 0.46)</td>\n",
              "      <td>(SBAR, 0.36)</td>\n",
              "      <td>(ADJP, 0.44)</td>\n",
              "      <td>(SBAR, 0.27)</td>\n",
              "      <td>(ADJP, 0.39)</td>\n",
              "      <td>(ADVP, 0.35)</td>\n",
              "      <td>(ADVP, 0.33)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(SBAR, 0.36)</td>\n",
              "      <td>(ADVP, 0.32)</td>\n",
              "      <td>(SBAR, 0.26)</td>\n",
              "      <td>(ADVP, 0.21)</td>\n",
              "      <td>(SBAR, 0.24)</td>\n",
              "      <td>(SBAR, 0.23)</td>\n",
              "      <td>(SBAR, 0.16)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(WHNP, 0.05)</td>\n",
              "      <td>(WHNP, 0.06)</td>\n",
              "      <td>(WHNP, 0.06)</td>\n",
              "      <td>(WHADVP, 0.19)</td>\n",
              "      <td>(WHADVP, 0.11)</td>\n",
              "      <td>(QP, 0.05)</td>\n",
              "      <td>(INTJ, 0.06)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(WHADVP, 0.03)</td>\n",
              "      <td>(QP, 0.04)</td>\n",
              "      <td>(WHADVP, 0.05)</td>\n",
              "      <td>(WHNP, 0.15)</td>\n",
              "      <td>(QP, 0.05)</td>\n",
              "      <td>(WHNP, 0.05)</td>\n",
              "      <td>(PRT, 0.05)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(QP, 0.03)</td>\n",
              "      <td>(WHADVP, 0.03)</td>\n",
              "      <td>(QP, 0.05)</td>\n",
              "      <td>(NP-TMP, 0.03)</td>\n",
              "      <td>(WHNP, 0.04)</td>\n",
              "      <td>(WHADVP, 0.04)</td>\n",
              "      <td>(QP, 0.04)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(PRT, 0.02)</td>\n",
              "      <td>(PRT, 0.02)</td>\n",
              "      <td>(PRT, 0.04)</td>\n",
              "      <td>(PRT, 0.03)</td>\n",
              "      <td>(NP-TMP, 0.04)</td>\n",
              "      <td>(PRT, 0.04)</td>\n",
              "      <td>(NP-TMP, 0.04)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(NP-TMP, 0.01)</td>\n",
              "      <td>(NP-TMP, 0.01)</td>\n",
              "      <td>(NP-TMP, 0.03)</td>\n",
              "      <td>(QP, 0.03)</td>\n",
              "      <td>(PRT, 0.03)</td>\n",
              "      <td>(NP-TMP, 0.03)</td>\n",
              "      <td>(WHNP, 0.03)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(X, 0.0)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "      <td>(INTJ, 0.01)</td>\n",
              "      <td>(INTJ, 0.01)</td>\n",
              "      <td>(INTJ, 0.01)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "      <td>(WHADVP, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(INTJ, 0.0)</td>\n",
              "      <td>(INTJ, 0.0)</td>\n",
              "      <td>(X, 0.0)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "      <td>(INTJ, 0.01)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(SBARQ, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal          others\n",
              "0         (NP, 5.03)      (NP, 5.36)  ...        (NP, 6.44)      (NP, 3.92)\n",
              "1         (VP, 2.75)      (VP, 2.95)  ...        (VP, 2.77)      (VP, 1.94)\n",
              "2       (ADJP, 0.87)      (PP, 0.73)  ...        (PP, 0.87)     (ADJP, 0.8)\n",
              "3         (PP, 0.74)     (ADJP, 0.7)  ...      (ADJP, 0.48)      (PP, 0.69)\n",
              "4       (ADVP, 0.46)    (SBAR, 0.36)  ...      (ADVP, 0.35)    (ADVP, 0.33)\n",
              "5       (SBAR, 0.36)    (ADVP, 0.32)  ...      (SBAR, 0.23)    (SBAR, 0.16)\n",
              "6       (WHNP, 0.05)    (WHNP, 0.06)  ...        (QP, 0.05)    (INTJ, 0.06)\n",
              "7     (WHADVP, 0.03)      (QP, 0.04)  ...      (WHNP, 0.05)     (PRT, 0.05)\n",
              "8         (QP, 0.03)  (WHADVP, 0.03)  ...    (WHADVP, 0.04)      (QP, 0.04)\n",
              "9        (PRT, 0.02)     (PRT, 0.02)  ...       (PRT, 0.04)  (NP-TMP, 0.04)\n",
              "10    (NP-TMP, 0.01)  (NP-TMP, 0.01)  ...    (NP-TMP, 0.03)    (WHNP, 0.03)\n",
              "11          (X, 0.0)       (X, 0.01)  ...         (X, 0.01)  (WHADVP, 0.01)\n",
              "12       (INTJ, 0.0)     (INTJ, 0.0)  ...      (INTJ, 0.01)       (X, 0.01)\n",
              "13      (SBARQ, 0.0)    (SBARQ, 0.0)  ...      (SBARQ, 0.0)   (SBARQ, 0.01)\n",
              "14          (S, 0.0)        (S, 0.0)  ...          (S, 0.0)        (S, 0.0)\n",
              "15        (PRN, 0.0)      (PRN, 0.0)  ...        (PRN, 0.0)      (PRN, 0.0)\n",
              "16       (FRAG, 0.0)     (FRAG, 0.0)  ...       (FRAG, 0.0)     (FRAG, 0.0)\n",
              "\n",
              "[17 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYZX9PjQDlJA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "465720bd-6240-4937-efc3-4f85d2e142cf"
      },
      "source": [
        "# @title In-Out (w/ stopwords): top-10 words for each category + overlap matrix {display-mode: \"form\"}\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "text_by_categories = GetTextByCategories(word=\"lemma\", show_pos=False, remove_punctuation=True, remove_stopwords=False)\n",
        "\n",
        "# Combine categories' sentences (list of words) into a single document (list)\n",
        "documents = {}\n",
        "for cat, sentences in text_by_categories.items():\n",
        "  documents[cat] = []\n",
        "  for s in sentences:\n",
        "    documents[cat].extend(s.tokens)\n",
        "\n",
        "words_by_zinout_with, _, _ = GetWordsByZInOut(documents)\n",
        "DisplayTopN(words_by_zinout_with.applymap(lambda t: Token(\"{lemma}\", t.properties)), 10, False)\n",
        "\n",
        "over = CalculateOverlap(words_by_zinout_with, 100)\n",
        "DisplayOverlapMatrix(over)\n",
        "upper = [over.iloc[ix,jx] for ix in range(over.shape[0]) for jx in range(over.shape[1]) if ix < jx]\n",
        "print(upper)\n",
        "\n",
        "tag_by_zinout = WordByScore2TagByScore(words_by_zinout_with, pos_key=\"pos\")\n",
        "display(tag_by_zinout.applymap(lambda e: e[1]))\n",
        "\n",
        "# ttt = tag_by_zinout[:6].applymap(lambda e: e[1])\n",
        "ttt = tag_by_zinout[:6].applymap(lambda e: (e[1], round(e[0], 2)))\n",
        "for ix, e in enumerate(ttt.iloc[-1, :]):\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"22ee\", 16)))\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"2507\", 16)))\n",
        "  ttt.iloc[-1, ix] = chr(int(\"2507\", 16))\n",
        "display(ttt)\n",
        "\n",
        "ancestor_by_zinout = WordByScore2TagByScore(words_by_zinout_with, pos_key=\"ancestor\")\n",
        "display(ancestor_by_zinout.applymap(lambda e: e[1]))\n",
        "\n",
        "# ttt = ancestor_by_zinout[:6].applymap(lambda e: e[1])\n",
        "ttt = ancestor_by_zinout[:6].applymap(lambda e: (e[1], round(e[0], 2)))\n",
        "for ix, e in enumerate(ttt.iloc[-1, :]):\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"22ee\", 16)))\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"2507\", 16)))\n",
        "  ttt.iloc[-1, ix] = chr(int(\"2507\", 16))\n",
        "display(ttt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>think</td>\n",
              "      <td>would</td>\n",
              "      <td>the</td>\n",
              "      <td>you</td>\n",
              "      <td>error</td>\n",
              "      <td>to</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i</td>\n",
              "      <td>to</td>\n",
              "      <td>we</td>\n",
              "      <td>do</td>\n",
              "      <td>i</td>\n",
              "      <td>you</td>\n",
              "      <td>for</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>not</td>\n",
              "      <td>a</td>\n",
              "      <td>in</td>\n",
              "      <td>what</td>\n",
              "      <td>the</td>\n",
              "      <td>_</td>\n",
              "      <td>you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>be</td>\n",
              "      <td>nice</td>\n",
              "      <td>of</td>\n",
              "      <td>there</td>\n",
              "      <td>problem</td>\n",
              "      <td>solution</td>\n",
              "      <td>help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>it</td>\n",
              "      <td>it</td>\n",
              "      <td>and</td>\n",
              "      <td>any</td>\n",
              "      <td>_</td>\n",
              "      <td>fix</td>\n",
              "      <td>thank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>but</td>\n",
              "      <td>add</td>\n",
              "      <td>on</td>\n",
              "      <td>how</td>\n",
              "      <td>issue</td>\n",
              "      <td>workaround</td>\n",
              "      <td>sorry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>like</td>\n",
              "      <td>if</td>\n",
              "      <td>have</td>\n",
              "      <td>can</td>\n",
              "      <td>when</td>\n",
              "      <td>work</td>\n",
              "      <td>hope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>seem</td>\n",
              "      <td>great</td>\n",
              "      <td>will</td>\n",
              "      <td>be</td>\n",
              "      <td>same</td>\n",
              "      <td>use</td>\n",
              "      <td>appreciate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>very</td>\n",
              "      <td>should</td>\n",
              "      <td>here</td>\n",
              "      <td>this</td>\n",
              "      <td>with</td>\n",
              "      <td>can</td>\n",
              "      <td>this</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>that</td>\n",
              "      <td>+1</td>\n",
              "      <td>currently</td>\n",
              "      <td>why</td>\n",
              "      <td>not</td>\n",
              "      <td>by</td>\n",
              "      <td>great</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal      others\n",
              "0             think           would  ...                to      thanks\n",
              "1                 i              to  ...               you         for\n",
              "2               not               a  ...                 _         you\n",
              "3                be            nice  ...          solution        help\n",
              "4                it              it  ...               fix       thank\n",
              "5               but             add  ...        workaround       sorry\n",
              "6              like              if  ...              work        hope\n",
              "7              seem           great  ...               use  appreciate\n",
              "8              very          should  ...               can        this\n",
              "9              that              +1  ...                by       great\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aspect evaluation</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.18</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature request</th>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information giving</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.13</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information seeking</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.06</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>problem discovery</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>solution proposal</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    aspect evaluation feature request  ... solution proposal others\n",
              "aspect evaluation                1.00            0.18  ...              0.04   0.13\n",
              "feature request                                  1.00  ...              0.08   0.13\n",
              "information giving                                     ...              0.16   0.04\n",
              "information seeking                                    ...              0.12   0.12\n",
              "problem discovery                                      ...              0.17   0.05\n",
              "solution proposal                                      ...              1.00   0.07\n",
              "others                                                 ...                     1.00\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.18, 0.05, 0.07, 0.05, 0.04, 0.13, 0.09, 0.07, 0.06, 0.08, 0.13, 0.06, 0.13, 0.16, 0.04, 0.06, 0.12, 0.12, 0.17, 0.05, 0.07]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>J</td>\n",
              "      <td>J</td>\n",
              "      <td>N</td>\n",
              "      <td>V</td>\n",
              "      <td>N</td>\n",
              "      <td>TO</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R</td>\n",
              "      <td>V</td>\n",
              "      <td>IN</td>\n",
              "      <td>WRB</td>\n",
              "      <td>CD</td>\n",
              "      <td>N</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>PRP</td>\n",
              "      <td>TO</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>WP</td>\n",
              "      <td>WRB</td>\n",
              "      <td>DT</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CC</td>\n",
              "      <td>N</td>\n",
              "      <td>DT</td>\n",
              "      <td>EX</td>\n",
              "      <td>R</td>\n",
              "      <td>PRP</td>\n",
              "      <td>UH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>FW</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>CD</td>\n",
              "      <td>N</td>\n",
              "      <td>CC</td>\n",
              "      <td>CD</td>\n",
              "      <td>CD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>SYM</td>\n",
              "      <td>WDT</td>\n",
              "      <td>RP</td>\n",
              "      <td>PRP</td>\n",
              "      <td>FW</td>\n",
              "      <td>RP</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>LS</td>\n",
              "      <td>LS</td>\n",
              "      <td>CC</td>\n",
              "      <td>CD</td>\n",
              "      <td>WDT</td>\n",
              "      <td>CC</td>\n",
              "      <td>RP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>POS</td>\n",
              "      <td>SYM</td>\n",
              "      <td>POS</td>\n",
              "      <td>SYM</td>\n",
              "      <td>SYM</td>\n",
              "      <td>FW</td>\n",
              "      <td>SYM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PRP$</td>\n",
              "      <td>FW</td>\n",
              "      <td>WDT</td>\n",
              "      <td>UH</td>\n",
              "      <td>UH</td>\n",
              "      <td>SYM</td>\n",
              "      <td>LS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>WDT</td>\n",
              "      <td>POS</td>\n",
              "      <td>R</td>\n",
              "      <td>LS</td>\n",
              "      <td>POS</td>\n",
              "      <td>LS</td>\n",
              "      <td>FW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>UH</td>\n",
              "      <td>UH</td>\n",
              "      <td>FW</td>\n",
              "      <td>FW</td>\n",
              "      <td>LS</td>\n",
              "      <td>POS</td>\n",
              "      <td>WP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>RP</td>\n",
              "      <td>RP</td>\n",
              "      <td>UH</td>\n",
              "      <td>POS</td>\n",
              "      <td>RP</td>\n",
              "      <td>UH</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>WP</td>\n",
              "      <td>CD</td>\n",
              "      <td>LS</td>\n",
              "      <td>RP</td>\n",
              "      <td>EX</td>\n",
              "      <td>WDT</td>\n",
              "      <td>PRP$</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>EX</td>\n",
              "      <td>WP</td>\n",
              "      <td>SYM</td>\n",
              "      <td>WDT</td>\n",
              "      <td>WP</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>WDT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>CD</td>\n",
              "      <td>EX</td>\n",
              "      <td>EX</td>\n",
              "      <td>DT</td>\n",
              "      <td>DT</td>\n",
              "      <td>WP</td>\n",
              "      <td>EX</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>WRB</td>\n",
              "      <td>CC</td>\n",
              "      <td>WP</td>\n",
              "      <td>TO</td>\n",
              "      <td>PRP</td>\n",
              "      <td>EX</td>\n",
              "      <td>WRB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>IN</td>\n",
              "      <td>WRB</td>\n",
              "      <td>WRB</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>PRP$</td>\n",
              "      <td>V</td>\n",
              "      <td>CC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>TO</td>\n",
              "      <td>IN</td>\n",
              "      <td>J</td>\n",
              "      <td>J</td>\n",
              "      <td>J</td>\n",
              "      <td>WRB</td>\n",
              "      <td>TO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>V</td>\n",
              "      <td>R</td>\n",
              "      <td>TO</td>\n",
              "      <td>CC</td>\n",
              "      <td>TO</td>\n",
              "      <td>R</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>N</td>\n",
              "      <td>DT</td>\n",
              "      <td>PRP</td>\n",
              "      <td>IN</td>\n",
              "      <td>IN</td>\n",
              "      <td>J</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>DT</td>\n",
              "      <td>PRP</td>\n",
              "      <td>V</td>\n",
              "      <td>R</td>\n",
              "      <td>V</td>\n",
              "      <td>IN</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal others\n",
              "0                  J               J  ...                TO      N\n",
              "1                  R               V  ...                 N      J\n",
              "2                PRP              TO  ...                DT    PRP\n",
              "3                 CC               N  ...               PRP     UH\n",
              "4                 FW            PRP$  ...                CD     CD\n",
              "5                SYM             WDT  ...                RP      R\n",
              "6                 LS              LS  ...                CC     RP\n",
              "7                POS             SYM  ...                FW    SYM\n",
              "8               PRP$              FW  ...               SYM     LS\n",
              "9                WDT             POS  ...                LS     FW\n",
              "10                UH              UH  ...               POS     WP\n",
              "11                RP              RP  ...                UH    POS\n",
              "12                WP              CD  ...               WDT   PRP$\n",
              "13                EX              WP  ...              PRP$    WDT\n",
              "14                CD              EX  ...                WP     EX\n",
              "15               WRB              CC  ...                EX    WRB\n",
              "16                IN             WRB  ...                 V     CC\n",
              "17                TO              IN  ...               WRB     TO\n",
              "18                 V               R  ...                 R     IN\n",
              "19                 N              DT  ...                 J     DT\n",
              "20                DT             PRP  ...                IN      V\n",
              "\n",
              "[21 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(J, 26.23)</td>\n",
              "      <td>(J, 21.69)</td>\n",
              "      <td>(N, 16.79)</td>\n",
              "      <td>(V, 20.19)</td>\n",
              "      <td>(N, 45.71)</td>\n",
              "      <td>(TO, 12.45)</td>\n",
              "      <td>(N, 46.26)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(R, 21.3)</td>\n",
              "      <td>(V, 18.29)</td>\n",
              "      <td>(IN, 12.3)</td>\n",
              "      <td>(WRB, 11.4)</td>\n",
              "      <td>(CD, 11.69)</td>\n",
              "      <td>(N, 12.39)</td>\n",
              "      <td>(J, 36.34)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(PRP, 7.76)</td>\n",
              "      <td>(TO, 9.74)</td>\n",
              "      <td>(PRP$, 4.87)</td>\n",
              "      <td>(WP, 9.61)</td>\n",
              "      <td>(WRB, 3.36)</td>\n",
              "      <td>(DT, 4.38)</td>\n",
              "      <td>(PRP, 18.76)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(CC, 1.96)</td>\n",
              "      <td>(N, 1.48)</td>\n",
              "      <td>(DT, 3.01)</td>\n",
              "      <td>(EX, 8.73)</td>\n",
              "      <td>(R, 2.58)</td>\n",
              "      <td>(PRP, 1.68)</td>\n",
              "      <td>(UH, 3.52)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(FW, 0.11)</td>\n",
              "      <td>(PRP$, 0.84)</td>\n",
              "      <td>(CD, 2.34)</td>\n",
              "      <td>(N, 7.71)</td>\n",
              "      <td>(CC, 2.47)</td>\n",
              "      <td>(CD, 1.52)</td>\n",
              "      <td>(CD, 3.32)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal        others\n",
              "0        (J, 26.23)      (J, 21.69)  ...       (TO, 12.45)    (N, 46.26)\n",
              "1         (R, 21.3)      (V, 18.29)  ...        (N, 12.39)    (J, 36.34)\n",
              "2       (PRP, 7.76)      (TO, 9.74)  ...        (DT, 4.38)  (PRP, 18.76)\n",
              "3        (CC, 1.96)       (N, 1.48)  ...       (PRP, 1.68)    (UH, 3.52)\n",
              "4        (FW, 0.11)    (PRP$, 0.84)  ...        (CD, 1.52)    (CD, 3.32)\n",
              "5                                  ...                              \n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADJP</td>\n",
              "      <td>VP</td>\n",
              "      <td>NP</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>NP</td>\n",
              "      <td>NP</td>\n",
              "      <td>ADJP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADVP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>PP</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>PP</td>\n",
              "      <td>NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SBAR</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>NP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>PRT</td>\n",
              "      <td>ADVP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>VP</td>\n",
              "      <td>QP</td>\n",
              "      <td>PRT</td>\n",
              "      <td>VP</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>QP</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SBARQ</td>\n",
              "      <td>X</td>\n",
              "      <td>QP</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>X</td>\n",
              "      <td>X</td>\n",
              "      <td>NP-TMP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>S</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>QP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>PRN</td>\n",
              "      <td>S</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>X</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>S</td>\n",
              "      <td>PRT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>FRAG</td>\n",
              "      <td>PRN</td>\n",
              "      <td>PRN</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>PRN</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>X</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>PRN</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>SBARQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>QP</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>PRN</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>S</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>QP</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>PRN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>PRT</td>\n",
              "      <td>X</td>\n",
              "      <td>PRT</td>\n",
              "      <td>PRT</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>FRAG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PRT</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>QP</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>WHNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>WHNP</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>PP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>WHADVP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>WHADVP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>VP</td>\n",
              "      <td>PP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>PP</td>\n",
              "      <td>PP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>SBAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NP</td>\n",
              "      <td>NP</td>\n",
              "      <td>VP</td>\n",
              "      <td>PP</td>\n",
              "      <td>VP</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>VP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal  others\n",
              "0               ADJP              VP  ...                NP    ADJP\n",
              "1               ADVP            ADJP  ...                PP      NP\n",
              "2               SBAR            SBAR  ...               PRT    ADVP\n",
              "3                 VP              QP  ...                QP    INTJ\n",
              "4              SBARQ               X  ...                 X  NP-TMP\n",
              "5                  S           SBARQ  ...             SBARQ      QP\n",
              "6                PRN               S  ...                 S     PRT\n",
              "7               FRAG             PRN  ...               PRN       X\n",
              "8                  X            FRAG  ...              FRAG   SBARQ\n",
              "9                 QP            INTJ  ...            NP-TMP       S\n",
              "10              INTJ          NP-TMP  ...              INTJ     PRN\n",
              "11            NP-TMP             PRT  ...              WHNP    FRAG\n",
              "12               PRT            WHNP  ...            WHADVP    WHNP\n",
              "13              WHNP          WHADVP  ...              ADVP  WHADVP\n",
              "14            WHADVP            ADVP  ...                VP      PP\n",
              "15                PP              PP  ...              ADJP    SBAR\n",
              "16                NP              NP  ...              SBAR      VP\n",
              "\n",
              "[17 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(ADJP, 26.16)</td>\n",
              "      <td>(VP, 22.66)</td>\n",
              "      <td>(NP, 21.25)</td>\n",
              "      <td>(WHADVP, 11.4)</td>\n",
              "      <td>(NP, 45.22)</td>\n",
              "      <td>(NP, 23.56)</td>\n",
              "      <td>(ADJP, 34.11)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(ADVP, 7.03)</td>\n",
              "      <td>(ADJP, 16.6)</td>\n",
              "      <td>(PP, 14.02)</td>\n",
              "      <td>(WHNP, 8.44)</td>\n",
              "      <td>(WHADVP, 3.36)</td>\n",
              "      <td>(PP, 0.98)</td>\n",
              "      <td>(NP, 30.49)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(SBAR, 6.06)</td>\n",
              "      <td>(SBAR, 6.79)</td>\n",
              "      <td>(ADVP, 5.34)</td>\n",
              "      <td>(NP, 7.77)</td>\n",
              "      <td>(ADVP, 2.43)</td>\n",
              "      <td>(PRT, 0.56)</td>\n",
              "      <td>(ADVP, 3.3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(VP, 1.8)</td>\n",
              "      <td>(QP, 0.52)</td>\n",
              "      <td>(PRT, 0.9)</td>\n",
              "      <td>(VP, 7.13)</td>\n",
              "      <td>(NP-TMP, 1.07)</td>\n",
              "      <td>(QP, 0.39)</td>\n",
              "      <td>(INTJ, 2.96)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(X, 0.06)</td>\n",
              "      <td>(QP, 0.55)</td>\n",
              "      <td>(NP-TMP, 0.45)</td>\n",
              "      <td>(X, 0.09)</td>\n",
              "      <td>(X, 0.29)</td>\n",
              "      <td>(NP-TMP, 2.35)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal          others\n",
              "0     (ADJP, 26.16)     (VP, 22.66)  ...       (NP, 23.56)   (ADJP, 34.11)\n",
              "1      (ADVP, 7.03)    (ADJP, 16.6)  ...        (PP, 0.98)     (NP, 30.49)\n",
              "2      (SBAR, 6.06)    (SBAR, 6.79)  ...       (PRT, 0.56)     (ADVP, 3.3)\n",
              "3         (VP, 1.8)      (QP, 0.52)  ...        (QP, 0.39)    (INTJ, 2.96)\n",
              "4      (SBARQ, 0.0)       (X, 0.06)  ...         (X, 0.29)  (NP-TMP, 2.35)\n",
              "5                                  ...                                \n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Kv2iWhIE-Bh"
      },
      "source": [
        "### Without stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJxKynD8Hzke",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b28d8230-ca1a-4b1a-e635-d1ae1b2354ee"
      },
      "source": [
        "# @title TFIDF (w/out stopwords): top-10 words for each category + overlap matrix {display-mode: \"form\"}\n",
        "# Q: What are the documents and what is the corpus?\n",
        "# A: There are a few options.\n",
        "#   One option is to consider each category as a document and the corpus as the\n",
        "# set of categories. That is to say that we combine each category's sentences\n",
        "# into a single string (document), thus obtaining 7 documents which form our\n",
        "# corpus.\n",
        "#  Another option is to ignore category boundaries. Each sentence is its own\n",
        "# document and the corpus is the set of sentencs. The TFIDF score should then\n",
        "# indicate the importance of a given word (e.g., 'the') relative to the sentence\n",
        "# rather than the category. Then, for each word which appears at least once in\n",
        "# a given category's sentences, we would obtain a score which could be something\n",
        "# like the mean of all of that words' tfidf scores (or the max). The issue with\n",
        "# this analysis is that it is unclear how to combine the scores or what they\n",
        "# mean.\n",
        "#   Finally, an option that one could consider would be to set the documents to\n",
        "# be the sentences of a category and the corpus to be only those sentences\n",
        "# belonging to that category. In that case, however, it is unclear what the\n",
        "# TFIDF represents. For example, let's say \"Thank you\" appears once in \"Solution\n",
        "# proposal.\" \"Thank\" may get a (decently) high score for that category would\n",
        "# consequently be considered (decently) meaningful. However, we know that the\n",
        "# \"other\" category has many occurrences of the word \"thank,\" meaning that it\n",
        "# isn't diagnostic of \"solution proposal\" (even though it would get a decent\n",
        "# score).\n",
        "\n",
        "# The difference between the first and second analysis is the difference between\n",
        "# calculating tfidf scores for a list of sentences of using a single document\n",
        "# comprised of those same sentences.\n",
        "\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "text_by_categories = GetTextByCategories(word=\"lemma\", show_pos=False, remove_punctuation=True, remove_stopwords=True)\n",
        "\n",
        "# (1) Documents = category; Corpus = all categories\n",
        "#   Combine all the sentences of a given category into a single document. Tfidf\n",
        "# then is just the colum corresponding to each category.\n",
        "\n",
        "# Combine categories' sentences (list of words) into a single document (list)\n",
        "documents = {}\n",
        "for cat, sentences in text_by_categories.items():\n",
        "  documents[cat] = []\n",
        "  for s in sentences:\n",
        "    documents[cat].extend(s.tokens)\n",
        "  \n",
        "words_by_tfidf_wout, tfidf, _ = GetWordsByTfidf(documents)\n",
        "pd.options.display.max_rows = 100\n",
        "DisplayTopN(words_by_tfidf_wout.applymap(lambda t: Token(\"{lemma}\", t.properties)), 10, False)\n",
        "\n",
        "# Overlap in top-100\n",
        "over = CalculateOverlap(words_by_tfidf_wout, 100)\n",
        "DisplayOverlapMatrix(over)\n",
        "\n",
        "tag_by_tfidf = WordByScore2TagByScore(words_by_tfidf_wout, pos_key=\"pos\")\n",
        "display(tag_by_tfidf.applymap(lambda e: (e[1], round(e[0], 2))))\n",
        "\n",
        "ancestor_by_tfidf = WordByScore2TagByScore(words_by_tfidf_wout, pos_key=\"ancestor\")\n",
        "display(ancestor_by_tfidf.applymap(lambda e: (e[1], round(e[0], 2))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>think</td>\n",
              "      <td>would</td>\n",
              "      <td>use</td>\n",
              "      <td>use</td>\n",
              "      <td>_</td>\n",
              "      <td>_</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>would</td>\n",
              "      <td>add</td>\n",
              "      <td>docker</td>\n",
              "      <td>could</td>\n",
              "      <td>error</td>\n",
              "      <td>use</td>\n",
              "      <td>thank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>like</td>\n",
              "      <td>like</td>\n",
              "      <td>code</td>\n",
              "      <td>would</td>\n",
              "      <td>problem</td>\n",
              "      <td>work</td>\n",
              "      <td>sorry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>use</td>\n",
              "      <td>+1</td>\n",
              "      <td>_</td>\n",
              "      <td>_</td>\n",
              "      <td>issue</td>\n",
              "      <td>fix</td>\n",
              "      <td>help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>seem</td>\n",
              "      <td>could</td>\n",
              "      <td>run</td>\n",
              "      <td>wonder</td>\n",
              "      <td>use</td>\n",
              "      <td>solution</td>\n",
              "      <td>hope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>make</td>\n",
              "      <td>need</td>\n",
              "      <td>build</td>\n",
              "      <td>know</td>\n",
              "      <td>get</td>\n",
              "      <td>would</td>\n",
              "      <td>appreciate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>good</td>\n",
              "      <td>nice</td>\n",
              "      <td>work</td>\n",
              "      <td>anyone</td>\n",
              "      <td>work</td>\n",
              "      <td>workaround</td>\n",
              "      <td>great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>_</td>\n",
              "      <td>use</td>\n",
              "      <td>file</td>\n",
              "      <td>version</td>\n",
              "      <td>fail</td>\n",
              "      <td>add</td>\n",
              "      <td>reply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>agree</td>\n",
              "      <td>support</td>\n",
              "      <td>see</td>\n",
              "      <td>file</td>\n",
              "      <td>try</td>\n",
              "      <td>qt</td>\n",
              "      <td>would</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>one</td>\n",
              "      <td>great</td>\n",
              "      <td>support</td>\n",
              "      <td>way</td>\n",
              "      <td>still</td>\n",
              "      <td>file</td>\n",
              "      <td>look</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal      others\n",
              "0             think           would  ...                 _      thanks\n",
              "1             would             add  ...               use       thank\n",
              "2              like            like  ...              work       sorry\n",
              "3               use              +1  ...               fix        help\n",
              "4              seem           could  ...          solution        hope\n",
              "5              make            need  ...             would  appreciate\n",
              "6              good            nice  ...        workaround       great\n",
              "7                 _             use  ...               add       reply\n",
              "8             agree         support  ...                qt       would\n",
              "9               one           great  ...              file        look\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aspect evaluation</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.54</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.35</td>\n",
              "      <td>0.40</td>\n",
              "      <td>0.25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature request</th>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.43</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information giving</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.56</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information seeking</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>problem discovery</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>solution proposal</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    aspect evaluation feature request  ... solution proposal others\n",
              "aspect evaluation                1.00            0.54  ...              0.40   0.25\n",
              "feature request                                  1.00  ...              0.44   0.21\n",
              "information giving                                     ...              0.53   0.21\n",
              "information seeking                                    ...              0.47   0.27\n",
              "problem discovery                                      ...              0.50   0.18\n",
              "solution proposal                                      ...              1.00   0.20\n",
              "others                                                 ...                     1.00\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(N, 9.71)</td>\n",
              "      <td>(N, 7.76)</td>\n",
              "      <td>(N, 15.54)</td>\n",
              "      <td>(N, 11.88)</td>\n",
              "      <td>(N, 10.37)</td>\n",
              "      <td>(N, 10.56)</td>\n",
              "      <td>(N, 3.67)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(V, 5.36)</td>\n",
              "      <td>(V, 4.45)</td>\n",
              "      <td>(V, 6.38)</td>\n",
              "      <td>(V, 6.39)</td>\n",
              "      <td>(V, 4.08)</td>\n",
              "      <td>(V, 5.31)</td>\n",
              "      <td>(V, 2.35)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(J, 3.96)</td>\n",
              "      <td>(J, 2.59)</td>\n",
              "      <td>(J, 3.59)</td>\n",
              "      <td>(J, 2.3)</td>\n",
              "      <td>(J, 1.88)</td>\n",
              "      <td>(J, 2.43)</td>\n",
              "      <td>(J, 1.41)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(R, 1.85)</td>\n",
              "      <td>(R, 0.84)</td>\n",
              "      <td>(R, 1.6)</td>\n",
              "      <td>(R, 0.87)</td>\n",
              "      <td>(CD, 1.2)</td>\n",
              "      <td>(R, 0.92)</td>\n",
              "      <td>(R, 0.56)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(IN, 0.56)</td>\n",
              "      <td>(CD, 0.4)</td>\n",
              "      <td>(CD, 1.18)</td>\n",
              "      <td>(CD, 0.86)</td>\n",
              "      <td>(R, 0.98)</td>\n",
              "      <td>(CD, 0.79)</td>\n",
              "      <td>(UH, 0.12)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(CD, 0.32)</td>\n",
              "      <td>(IN, 0.35)</td>\n",
              "      <td>(IN, 0.44)</td>\n",
              "      <td>(IN, 0.29)</td>\n",
              "      <td>(IN, 0.26)</td>\n",
              "      <td>(IN, 0.28)</td>\n",
              "      <td>(IN, 0.06)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(CC, 0.1)</td>\n",
              "      <td>(CC, 0.04)</td>\n",
              "      <td>(CC, 0.1)</td>\n",
              "      <td>(FW, 0.06)</td>\n",
              "      <td>(FW, 0.06)</td>\n",
              "      <td>(FW, 0.07)</td>\n",
              "      <td>(CD, 0.05)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(FW, 0.06)</td>\n",
              "      <td>(FW, 0.03)</td>\n",
              "      <td>(FW, 0.1)</td>\n",
              "      <td>(UH, 0.06)</td>\n",
              "      <td>(CC, 0.05)</td>\n",
              "      <td>(DT, 0.06)</td>\n",
              "      <td>(SYM, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(DT, 0.06)</td>\n",
              "      <td>(DT, 0.03)</td>\n",
              "      <td>(POS, 0.09)</td>\n",
              "      <td>(CC, 0.05)</td>\n",
              "      <td>(DT, 0.05)</td>\n",
              "      <td>(CC, 0.06)</td>\n",
              "      <td>(CC, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(POS, 0.05)</td>\n",
              "      <td>(POS, 0.03)</td>\n",
              "      <td>(UH, 0.06)</td>\n",
              "      <td>(DT, 0.03)</td>\n",
              "      <td>(POS, 0.04)</td>\n",
              "      <td>(RP, 0.04)</td>\n",
              "      <td>(POS, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(UH, 0.02)</td>\n",
              "      <td>(SYM, 0.02)</td>\n",
              "      <td>(DT, 0.04)</td>\n",
              "      <td>(POS, 0.03)</td>\n",
              "      <td>(UH, 0.03)</td>\n",
              "      <td>(SYM, 0.04)</td>\n",
              "      <td>(WRB, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(SYM, 0.02)</td>\n",
              "      <td>(UH, 0.02)</td>\n",
              "      <td>(RP, 0.02)</td>\n",
              "      <td>(SYM, 0.03)</td>\n",
              "      <td>(SYM, 0.02)</td>\n",
              "      <td>(POS, 0.04)</td>\n",
              "      <td>(WDT, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(RP, 0.01)</td>\n",
              "      <td>(LS, 0.01)</td>\n",
              "      <td>(SYM, 0.01)</td>\n",
              "      <td>(RP, 0.02)</td>\n",
              "      <td>(RP, 0.01)</td>\n",
              "      <td>(UH, 0.03)</td>\n",
              "      <td>(TO, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(WDT, 0.01)</td>\n",
              "      <td>(WDT, 0.01)</td>\n",
              "      <td>(TO, 0.01)</td>\n",
              "      <td>(LS, 0.01)</td>\n",
              "      <td>(PRP, 0.0)</td>\n",
              "      <td>(LS, 0.01)</td>\n",
              "      <td>(RP, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(TO, 0.01)</td>\n",
              "      <td>(TO, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(TO, 0.0)</td>\n",
              "      <td>(WDT, 0.0)</td>\n",
              "      <td>(WDT, 0.01)</td>\n",
              "      <td>(PRP, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(WRB, 0.0)</td>\n",
              "      <td>(RP, 0.0)</td>\n",
              "      <td>(WDT, 0.0)</td>\n",
              "      <td>(WDT, 0.0)</td>\n",
              "      <td>(WRB, 0.0)</td>\n",
              "      <td>(WRB, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(PRP, 0.0)</td>\n",
              "      <td>(WRB, 0.0)</td>\n",
              "      <td>(WRB, 0.0)</td>\n",
              "      <td>(WRB, 0.0)</td>\n",
              "      <td>(TO, 0.0)</td>\n",
              "      <td>(TO, 0.0)</td>\n",
              "      <td>(FW, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(PRP, 0.0)</td>\n",
              "      <td>(PRP, 0.0)</td>\n",
              "      <td>(PRP, 0.0)</td>\n",
              "      <td>(LS, 0.0)</td>\n",
              "      <td>(PRP, 0.0)</td>\n",
              "      <td>(DT, 0.0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal       others\n",
              "0          (N, 9.71)       (N, 7.76)  ...        (N, 10.56)    (N, 3.67)\n",
              "1          (V, 5.36)       (V, 4.45)  ...         (V, 5.31)    (V, 2.35)\n",
              "2          (J, 3.96)       (J, 2.59)  ...         (J, 2.43)    (J, 1.41)\n",
              "3          (R, 1.85)       (R, 0.84)  ...         (R, 0.92)    (R, 0.56)\n",
              "4         (IN, 0.56)       (CD, 0.4)  ...        (CD, 0.79)   (UH, 0.12)\n",
              "5         (CD, 0.32)      (IN, 0.35)  ...        (IN, 0.28)   (IN, 0.06)\n",
              "6          (CC, 0.1)      (CC, 0.04)  ...        (FW, 0.07)   (CD, 0.05)\n",
              "7         (FW, 0.06)      (FW, 0.03)  ...        (DT, 0.06)  (SYM, 0.01)\n",
              "8         (DT, 0.06)      (DT, 0.03)  ...        (CC, 0.06)   (CC, 0.01)\n",
              "9        (POS, 0.05)     (POS, 0.03)  ...        (RP, 0.04)  (POS, 0.01)\n",
              "10        (UH, 0.02)     (SYM, 0.02)  ...       (SYM, 0.04)   (WRB, 0.0)\n",
              "11       (SYM, 0.02)      (UH, 0.02)  ...       (POS, 0.04)   (WDT, 0.0)\n",
              "12        (RP, 0.01)      (LS, 0.01)  ...        (UH, 0.03)    (TO, 0.0)\n",
              "13       (WDT, 0.01)     (WDT, 0.01)  ...        (LS, 0.01)    (RP, 0.0)\n",
              "14        (TO, 0.01)       (TO, 0.0)  ...       (WDT, 0.01)   (PRP, 0.0)\n",
              "15        (WRB, 0.0)       (RP, 0.0)  ...        (WRB, 0.0)    (LS, 0.0)\n",
              "16        (PRP, 0.0)      (WRB, 0.0)  ...         (TO, 0.0)    (FW, 0.0)\n",
              "17         (LS, 0.0)      (PRP, 0.0)  ...        (PRP, 0.0)    (DT, 0.0)\n",
              "\n",
              "[18 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(NP, 12.06)</td>\n",
              "      <td>(NP, 9.68)</td>\n",
              "      <td>(NP, 19.49)</td>\n",
              "      <td>(NP, 14.33)</td>\n",
              "      <td>(NP, 12.93)</td>\n",
              "      <td>(NP, 13.45)</td>\n",
              "      <td>(NP, 4.1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(VP, 5.15)</td>\n",
              "      <td>(VP, 4.27)</td>\n",
              "      <td>(VP, 5.97)</td>\n",
              "      <td>(VP, 6.02)</td>\n",
              "      <td>(VP, 3.82)</td>\n",
              "      <td>(VP, 4.84)</td>\n",
              "      <td>(VP, 2.24)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(ADJP, 2.56)</td>\n",
              "      <td>(ADJP, 1.39)</td>\n",
              "      <td>(ADVP, 1.49)</td>\n",
              "      <td>(ADJP, 1.03)</td>\n",
              "      <td>(ADVP, 0.88)</td>\n",
              "      <td>(ADJP, 0.95)</td>\n",
              "      <td>(ADJP, 1.17)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(ADVP, 1.53)</td>\n",
              "      <td>(ADVP, 0.72)</td>\n",
              "      <td>(ADJP, 1.41)</td>\n",
              "      <td>(ADVP, 0.77)</td>\n",
              "      <td>(ADJP, 0.82)</td>\n",
              "      <td>(ADVP, 0.77)</td>\n",
              "      <td>(ADVP, 0.45)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(SBAR, 0.42)</td>\n",
              "      <td>(SBAR, 0.25)</td>\n",
              "      <td>(PP, 0.27)</td>\n",
              "      <td>(PP, 0.3)</td>\n",
              "      <td>(PP, 0.18)</td>\n",
              "      <td>(PP, 0.24)</td>\n",
              "      <td>(INTJ, 0.1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(PP, 0.24)</td>\n",
              "      <td>(PP, 0.17)</td>\n",
              "      <td>(SBAR, 0.18)</td>\n",
              "      <td>(SBAR, 0.16)</td>\n",
              "      <td>(SBAR, 0.16)</td>\n",
              "      <td>(SBAR, 0.13)</td>\n",
              "      <td>(NP-TMP, 0.07)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(QP, 0.05)</td>\n",
              "      <td>(QP, 0.04)</td>\n",
              "      <td>(NP-TMP, 0.14)</td>\n",
              "      <td>(NP-TMP, 0.13)</td>\n",
              "      <td>(NP-TMP, 0.11)</td>\n",
              "      <td>(NP-TMP, 0.07)</td>\n",
              "      <td>(SBAR, 0.05)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>(NP-TMP, 0.03)</td>\n",
              "      <td>(NP-TMP, 0.03)</td>\n",
              "      <td>(QP, 0.1)</td>\n",
              "      <td>(INTJ, 0.04)</td>\n",
              "      <td>(QP, 0.08)</td>\n",
              "      <td>(QP, 0.06)</td>\n",
              "      <td>(PP, 0.03)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(WHNP, 0.02)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "      <td>(INTJ, 0.04)</td>\n",
              "      <td>(QP, 0.04)</td>\n",
              "      <td>(INTJ, 0.02)</td>\n",
              "      <td>(PRT, 0.04)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(X, 0.01)</td>\n",
              "      <td>(INTJ, 0.01)</td>\n",
              "      <td>(PRT, 0.02)</td>\n",
              "      <td>(X, 0.03)</td>\n",
              "      <td>(X, 0.02)</td>\n",
              "      <td>(X, 0.04)</td>\n",
              "      <td>(WHNP, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(WHADVP, 0.0)</td>\n",
              "      <td>(WHNP, 0.01)</td>\n",
              "      <td>(WHNP, 0.01)</td>\n",
              "      <td>(PRT, 0.02)</td>\n",
              "      <td>(WHNP, 0.01)</td>\n",
              "      <td>(INTJ, 0.02)</td>\n",
              "      <td>(SBARQ, 0.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>(INTJ, 0.0)</td>\n",
              "      <td>(PRT, 0.0)</td>\n",
              "      <td>(X, 0.01)</td>\n",
              "      <td>(WHNP, 0.01)</td>\n",
              "      <td>(PRT, 0.01)</td>\n",
              "      <td>(WHNP, 0.01)</td>\n",
              "      <td>(WHADVP, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(PRT, 0.0)</td>\n",
              "      <td>(WHADVP, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(S, 0.01)</td>\n",
              "      <td>(WHADVP, 0.0)</td>\n",
              "      <td>(WHADVP, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(WHADVP, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(QP, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(WHADVP, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(PRT, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(SBARQ, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "      <td>(PRN, 0.0)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(S, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "      <td>(FRAG, 0.0)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal          others\n",
              "0        (NP, 12.06)      (NP, 9.68)  ...       (NP, 13.45)       (NP, 4.1)\n",
              "1         (VP, 5.15)      (VP, 4.27)  ...        (VP, 4.84)      (VP, 2.24)\n",
              "2       (ADJP, 2.56)    (ADJP, 1.39)  ...      (ADJP, 0.95)    (ADJP, 1.17)\n",
              "3       (ADVP, 1.53)    (ADVP, 0.72)  ...      (ADVP, 0.77)    (ADVP, 0.45)\n",
              "4       (SBAR, 0.42)    (SBAR, 0.25)  ...        (PP, 0.24)     (INTJ, 0.1)\n",
              "5         (PP, 0.24)      (PP, 0.17)  ...      (SBAR, 0.13)  (NP-TMP, 0.07)\n",
              "6         (QP, 0.05)      (QP, 0.04)  ...    (NP-TMP, 0.07)    (SBAR, 0.05)\n",
              "7     (NP-TMP, 0.03)  (NP-TMP, 0.03)  ...        (QP, 0.06)      (PP, 0.03)\n",
              "8       (WHNP, 0.02)       (X, 0.01)  ...       (PRT, 0.04)       (X, 0.01)\n",
              "9          (X, 0.01)    (INTJ, 0.01)  ...         (X, 0.04)    (WHNP, 0.01)\n",
              "10     (WHADVP, 0.0)    (WHNP, 0.01)  ...      (INTJ, 0.02)   (SBARQ, 0.01)\n",
              "11       (INTJ, 0.0)      (PRT, 0.0)  ...      (WHNP, 0.01)   (WHADVP, 0.0)\n",
              "12        (PRT, 0.0)   (WHADVP, 0.0)  ...     (WHADVP, 0.0)        (S, 0.0)\n",
              "13      (SBARQ, 0.0)    (SBARQ, 0.0)  ...      (SBARQ, 0.0)       (QP, 0.0)\n",
              "14          (S, 0.0)        (S, 0.0)  ...          (S, 0.0)      (PRT, 0.0)\n",
              "15        (PRN, 0.0)      (PRN, 0.0)  ...        (PRN, 0.0)      (PRN, 0.0)\n",
              "16       (FRAG, 0.0)     (FRAG, 0.0)  ...       (FRAG, 0.0)     (FRAG, 0.0)\n",
              "\n",
              "[17 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvGdXcgF4HuJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17bfb43c-7c1a-4ef6-eb52-06b44be1390a"
      },
      "source": [
        "# @title In-Out (w/out stopwords): top-10 words for each category + overlap matrix {display-mode: \"form\"}\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "text_by_categories = GetTextByCategories(word=\"lemma\", show_pos=False, remove_punctuation=True, remove_stopwords=True)\n",
        "\n",
        "# Combine categories' sentences (list of words) into a single document (list)\n",
        "documents = {}\n",
        "for cat, sentences in text_by_categories.items():\n",
        "  documents[cat] = []\n",
        "  for s in sentences:\n",
        "    documents[cat].extend(s.tokens)\n",
        "\n",
        "words_by_zinout_wout, _, _ = GetWordsByZInOut(documents)\n",
        "DisplayTopN(words_by_zinout_wout.applymap(lambda t: Token(\"{lemma}\", t.properties)), 10, False)\n",
        "\n",
        "over = CalculateOverlap(words_by_zinout_wout, 100)\n",
        "DisplayOverlapMatrix(over)\n",
        "upper = [over.iloc[ix,jx] for ix in range(over.shape[0]) for jx in range(over.shape[1]) if ix < jx]\n",
        "print(upper)\n",
        "\n",
        "tag_by_zinout = WordByScore2TagByScore(words_by_zinout_wout, pos_key=\"pos\")\n",
        "display(tag_by_zinout.applymap(lambda e: e[1]))\n",
        "\n",
        "# ttt = tag_by_zinout[:6].applymap(lambda e: e[1])\n",
        "ttt = tag_by_zinout[:6].applymap(lambda e: (e[1], round(e[0], 2)))\n",
        "for ix, e in enumerate(ttt.iloc[-1, :]):\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"22ee\", 16)))\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"2507\", 16)))\n",
        "  ttt.iloc[-1, ix] = chr(int(\"2507\", 16))\n",
        "display(ttt)\n",
        "\n",
        "ancestor_by_zinout = WordByScore2TagByScore(words_by_zinout_wout, pos_key=\"ancestor\")\n",
        "display(ancestor_by_zinout.applymap(lambda e: e[1]))\n",
        "\n",
        "# ttt = ancestor_by_zinout[:6].applymap(lambda e: e[1])\n",
        "ttt = ancestor_by_zinout[:6].applymap(lambda e: (e[1], round(e[0], 2)))\n",
        "for ix, e in enumerate(ttt.iloc[-1, :]):\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"22ee\", 16)))\n",
        "  # ttt.iloc[-1, ix] = (\"\", chr(int(\"2507\", 16)))\n",
        "  ttt.iloc[-1, ix] = chr(int(\"2507\", 16))\n",
        "display(ttt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>think</td>\n",
              "      <td>would</td>\n",
              "      <td>use</td>\n",
              "      <td>anyone</td>\n",
              "      <td>error</td>\n",
              "      <td>solution</td>\n",
              "      <td>thanks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>like</td>\n",
              "      <td>nice</td>\n",
              "      <td>code</td>\n",
              "      <td>could</td>\n",
              "      <td>problem</td>\n",
              "      <td>fix</td>\n",
              "      <td>thank</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>seem</td>\n",
              "      <td>+1</td>\n",
              "      <td>currently</td>\n",
              "      <td>know</td>\n",
              "      <td>issue</td>\n",
              "      <td>workaround</td>\n",
              "      <td>help</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>idea</td>\n",
              "      <td>great</td>\n",
              "      <td>see</td>\n",
              "      <td>wonder</td>\n",
              "      <td>_</td>\n",
              "      <td>_</td>\n",
              "      <td>sorry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>good</td>\n",
              "      <td>add</td>\n",
              "      <td>docker</td>\n",
              "      <td>way</td>\n",
              "      <td>get</td>\n",
              "      <td>work</td>\n",
              "      <td>hope</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>agree</td>\n",
              "      <td>feature</td>\n",
              "      <td>note</td>\n",
              "      <td>please</td>\n",
              "      <td>fail</td>\n",
              "      <td>solve</td>\n",
              "      <td>appreciate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>sure</td>\n",
              "      <td>need</td>\n",
              "      <td>release</td>\n",
              "      <td>mean</td>\n",
              "      <td>still</td>\n",
              "      <td>qt</td>\n",
              "      <td>great</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>really</td>\n",
              "      <td>could</td>\n",
              "      <td>build</td>\n",
              "      <td>reason</td>\n",
              "      <td>try</td>\n",
              "      <td>add</td>\n",
              "      <td>reply</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>probably</td>\n",
              "      <td>support</td>\n",
              "      <td>test</td>\n",
              "      <td>version</td>\n",
              "      <td>crash</td>\n",
              "      <td>remove</td>\n",
              "      <td>suggestion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>guess</td>\n",
              "      <td>useful</td>\n",
              "      <td>support</td>\n",
              "      <td>update</td>\n",
              "      <td>bug</td>\n",
              "      <td>instead</td>\n",
              "      <td>lot</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal      others\n",
              "0             think           would  ...          solution      thanks\n",
              "1              like            nice  ...               fix       thank\n",
              "2              seem              +1  ...        workaround        help\n",
              "3              idea           great  ...                 _       sorry\n",
              "4              good             add  ...              work        hope\n",
              "5             agree         feature  ...             solve  appreciate\n",
              "6              sure            need  ...                qt       great\n",
              "7            really           could  ...               add       reply\n",
              "8          probably         support  ...            remove  suggestion\n",
              "9             guess          useful  ...           instead         lot\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>aspect evaluation</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.08</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.03</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>feature request</th>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.02</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information giving</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.17</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.09</td>\n",
              "      <td>0.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>information seeking</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.04</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>problem discovery</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.05</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>solution proposal</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>others</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>1.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    aspect evaluation feature request  ... solution proposal others\n",
              "aspect evaluation                1.00            0.08  ...              0.02   0.09\n",
              "feature request                                  1.00  ...              0.04   0.06\n",
              "information giving                                     ...              0.09   0.01\n",
              "information seeking                                    ...              0.10   0.06\n",
              "problem discovery                                      ...              0.05   0.00\n",
              "solution proposal                                      ...              1.00   0.00\n",
              "others                                                 ...                     1.00\n",
              "\n",
              "[7 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[0.08, 0.03, 0.03, 0.0, 0.02, 0.09, 0.05, 0.04, 0.02, 0.04, 0.06, 0.17, 0.05, 0.09, 0.01, 0.04, 0.1, 0.06, 0.05, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>J</td>\n",
              "      <td>J</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R</td>\n",
              "      <td>CD</td>\n",
              "      <td>POS</td>\n",
              "      <td>V</td>\n",
              "      <td>CD</td>\n",
              "      <td>CD</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>IN</td>\n",
              "      <td>SYM</td>\n",
              "      <td>R</td>\n",
              "      <td>CD</td>\n",
              "      <td>FW</td>\n",
              "      <td>J</td>\n",
              "      <td>CD</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CC</td>\n",
              "      <td>FW</td>\n",
              "      <td>CC</td>\n",
              "      <td>UH</td>\n",
              "      <td>SYM</td>\n",
              "      <td>RP</td>\n",
              "      <td>UH</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>DT</td>\n",
              "      <td>LS</td>\n",
              "      <td>UH</td>\n",
              "      <td>SYM</td>\n",
              "      <td>PRP</td>\n",
              "      <td>FW</td>\n",
              "      <td>SYM</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>WDT</td>\n",
              "      <td>TO</td>\n",
              "      <td>FW</td>\n",
              "      <td>LS</td>\n",
              "      <td>WRB</td>\n",
              "      <td>SYM</td>\n",
              "      <td>FW</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>WRB</td>\n",
              "      <td>WDT</td>\n",
              "      <td>TO</td>\n",
              "      <td>TO</td>\n",
              "      <td>WDT</td>\n",
              "      <td>DT</td>\n",
              "      <td>WRB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TO</td>\n",
              "      <td>WRB</td>\n",
              "      <td>RP</td>\n",
              "      <td>WRB</td>\n",
              "      <td>DT</td>\n",
              "      <td>LS</td>\n",
              "      <td>PRP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>FW</td>\n",
              "      <td>PRP</td>\n",
              "      <td>WRB</td>\n",
              "      <td>PRP</td>\n",
              "      <td>TO</td>\n",
              "      <td>WDT</td>\n",
              "      <td>TO</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>SYM</td>\n",
              "      <td>RP</td>\n",
              "      <td>PRP</td>\n",
              "      <td>FW</td>\n",
              "      <td>LS</td>\n",
              "      <td>WRB</td>\n",
              "      <td>LS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>PRP</td>\n",
              "      <td>DT</td>\n",
              "      <td>LS</td>\n",
              "      <td>RP</td>\n",
              "      <td>UH</td>\n",
              "      <td>PRP</td>\n",
              "      <td>WDT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LS</td>\n",
              "      <td>UH</td>\n",
              "      <td>WDT</td>\n",
              "      <td>WDT</td>\n",
              "      <td>RP</td>\n",
              "      <td>TO</td>\n",
              "      <td>RP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>POS</td>\n",
              "      <td>CC</td>\n",
              "      <td>DT</td>\n",
              "      <td>DT</td>\n",
              "      <td>POS</td>\n",
              "      <td>UH</td>\n",
              "      <td>CC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>RP</td>\n",
              "      <td>POS</td>\n",
              "      <td>SYM</td>\n",
              "      <td>POS</td>\n",
              "      <td>CC</td>\n",
              "      <td>CC</td>\n",
              "      <td>DT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>UH</td>\n",
              "      <td>IN</td>\n",
              "      <td>IN</td>\n",
              "      <td>CC</td>\n",
              "      <td>R</td>\n",
              "      <td>POS</td>\n",
              "      <td>POS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>CD</td>\n",
              "      <td>N</td>\n",
              "      <td>CD</td>\n",
              "      <td>IN</td>\n",
              "      <td>IN</td>\n",
              "      <td>IN</td>\n",
              "      <td>R</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>V</td>\n",
              "      <td>R</td>\n",
              "      <td>V</td>\n",
              "      <td>J</td>\n",
              "      <td>J</td>\n",
              "      <td>R</td>\n",
              "      <td>IN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>N</td>\n",
              "      <td>V</td>\n",
              "      <td>J</td>\n",
              "      <td>R</td>\n",
              "      <td>V</td>\n",
              "      <td>V</td>\n",
              "      <td>V</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal others\n",
              "0                  J               J  ...                 N      J\n",
              "1                  R              CD  ...                CD      N\n",
              "2                 IN             SYM  ...                 J     CD\n",
              "3                 CC              FW  ...                RP     UH\n",
              "4                 DT              LS  ...                FW    SYM\n",
              "5                WDT              TO  ...               SYM     FW\n",
              "6                WRB             WDT  ...                DT    WRB\n",
              "7                 TO             WRB  ...                LS    PRP\n",
              "8                 FW             PRP  ...               WDT     TO\n",
              "9                SYM              RP  ...               WRB     LS\n",
              "10               PRP              DT  ...               PRP    WDT\n",
              "11                LS              UH  ...                TO     RP\n",
              "12               POS              CC  ...                UH     CC\n",
              "13                RP             POS  ...                CC     DT\n",
              "14                UH              IN  ...               POS    POS\n",
              "15                CD               N  ...                IN      R\n",
              "16                 V               R  ...                 R     IN\n",
              "17                 N               V  ...                 V      V\n",
              "\n",
              "[18 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(J, 99.56)</td>\n",
              "      <td>(J, 93.92)</td>\n",
              "      <td>(N, 48.1)</td>\n",
              "      <td>(N, 39.87)</td>\n",
              "      <td>(N, 123.28)</td>\n",
              "      <td>(N, 41.18)</td>\n",
              "      <td>(J, 112.38)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(R, 48.08)</td>\n",
              "      <td>(CD, 20.27)</td>\n",
              "      <td>(POS, 4.19)</td>\n",
              "      <td>(V, 34.25)</td>\n",
              "      <td>(CD, 54.24)</td>\n",
              "      <td>(CD, 23.75)</td>\n",
              "      <td>(N, 57.89)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(IN, 17.47)</td>\n",
              "      <td>(SYM, 1.3)</td>\n",
              "      <td>(R, 3.5)</td>\n",
              "      <td>(CD, 9.98)</td>\n",
              "      <td>(FW, 1.36)</td>\n",
              "      <td>(J, 5.63)</td>\n",
              "      <td>(CD, 35.96)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(CC, 2.35)</td>\n",
              "      <td>(FW, 0.57)</td>\n",
              "      <td>(CC, 1.91)</td>\n",
              "      <td>(UH, 0.92)</td>\n",
              "      <td>(SYM, 1.08)</td>\n",
              "      <td>(RP, 2.64)</td>\n",
              "      <td>(UH, 6.04)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(DT, 0.68)</td>\n",
              "      <td>(LS, 0.54)</td>\n",
              "      <td>(UH, 1.14)</td>\n",
              "      <td>(SYM, 0.57)</td>\n",
              "      <td>(PRP, 0.22)</td>\n",
              "      <td>(FW, 1.83)</td>\n",
              "      <td>(SYM, 2.15)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal       others\n",
              "0        (J, 99.56)      (J, 93.92)  ...        (N, 41.18)  (J, 112.38)\n",
              "1        (R, 48.08)     (CD, 20.27)  ...       (CD, 23.75)   (N, 57.89)\n",
              "2       (IN, 17.47)      (SYM, 1.3)  ...         (J, 5.63)  (CD, 35.96)\n",
              "3        (CC, 2.35)      (FW, 0.57)  ...        (RP, 2.64)   (UH, 6.04)\n",
              "4        (DT, 0.68)      (LS, 0.54)  ...        (FW, 1.83)  (SYM, 2.15)\n",
              "5                                  ...                             \n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ADJP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>NP</td>\n",
              "      <td>NP</td>\n",
              "      <td>NP</td>\n",
              "      <td>NP</td>\n",
              "      <td>NP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ADVP</td>\n",
              "      <td>NP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>VP</td>\n",
              "      <td>QP</td>\n",
              "      <td>PRT</td>\n",
              "      <td>ADJP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SBAR</td>\n",
              "      <td>QP</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>PP</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>X</td>\n",
              "      <td>INTJ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>QP</td>\n",
              "      <td>X</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>X</td>\n",
              "      <td>QP</td>\n",
              "      <td>NP-TMP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WHNP</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>PRT</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>PP</td>\n",
              "      <td>QP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>WHADVP</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>PRN</td>\n",
              "      <td>X</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>X</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>SBARQ</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>S</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>SBARQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "      <td>QP</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>S</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>WHADVP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>PRN</td>\n",
              "      <td>PRN</td>\n",
              "      <td>WHADVP</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>PRN</td>\n",
              "      <td>S</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>FRAG</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>SBARQ</td>\n",
              "      <td>PRN</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>PRN</td>\n",
              "      <td>PRN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>X</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>S</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>FRAG</td>\n",
              "      <td>FRAG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>PRT</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>PRT</td>\n",
              "      <td>PRT</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>WHNP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PP</td>\n",
              "      <td>PRT</td>\n",
              "      <td>PP</td>\n",
              "      <td>QP</td>\n",
              "      <td>PP</td>\n",
              "      <td>INTJ</td>\n",
              "      <td>PRT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>X</td>\n",
              "      <td>WHNP</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>PP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>NP-TMP</td>\n",
              "      <td>PP</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>SBAR</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>ADVP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>VP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>VP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>SBAR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>NP</td>\n",
              "      <td>VP</td>\n",
              "      <td>ADJP</td>\n",
              "      <td>ADVP</td>\n",
              "      <td>VP</td>\n",
              "      <td>VP</td>\n",
              "      <td>VP</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   aspect evaluation feature request  ... solution proposal  others\n",
              "0               ADJP            ADJP  ...                NP      NP\n",
              "1               ADVP              NP  ...               PRT    ADJP\n",
              "2               SBAR              QP  ...                 X    INTJ\n",
              "3                 QP               X  ...                QP  NP-TMP\n",
              "4               WHNP            SBAR  ...                PP      QP\n",
              "5             WHADVP          WHADVP  ...            NP-TMP       X\n",
              "6              SBARQ           SBARQ  ...            WHADVP   SBARQ\n",
              "7                  S               S  ...             SBARQ  WHADVP\n",
              "8                PRN             PRN  ...                 S       S\n",
              "9               FRAG            FRAG  ...               PRN     PRN\n",
              "10                 X            WHNP  ...              FRAG    FRAG\n",
              "11               PRT            INTJ  ...              WHNP    WHNP\n",
              "12                PP             PRT  ...              INTJ     PRT\n",
              "13              INTJ          NP-TMP  ...              SBAR      PP\n",
              "14            NP-TMP              PP  ...              ADJP    ADVP\n",
              "15                VP            ADVP  ...              ADVP    SBAR\n",
              "16                NP              VP  ...                VP      VP\n",
              "\n",
              "[17 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(ADJP, 87.07)</td>\n",
              "      <td>(ADJP, 45.2)</td>\n",
              "      <td>(NP, 57.86)</td>\n",
              "      <td>(NP, 32.4)</td>\n",
              "      <td>(NP, 170.73)</td>\n",
              "      <td>(NP, 106.08)</td>\n",
              "      <td>(NP, 112.1)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(ADVP, 36.09)</td>\n",
              "      <td>(NP, 34.18)</td>\n",
              "      <td>(ADVP, 10.78)</td>\n",
              "      <td>(VP, 31.49)</td>\n",
              "      <td>(QP, 3.87)</td>\n",
              "      <td>(PRT, 2.62)</td>\n",
              "      <td>(ADJP, 71.3)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>(SBAR, 18.83)</td>\n",
              "      <td>(QP, 3.19)</td>\n",
              "      <td>(NP-TMP, 1.64)</td>\n",
              "      <td>(PP, 4.83)</td>\n",
              "      <td>(NP-TMP, 3.55)</td>\n",
              "      <td>(X, 1.55)</td>\n",
              "      <td>(INTJ, 5.56)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(QP, 0.44)</td>\n",
              "      <td>(X, 0.89)</td>\n",
              "      <td>(INTJ, 0.8)</td>\n",
              "      <td>(NP-TMP, 2.07)</td>\n",
              "      <td>(X, 0.78)</td>\n",
              "      <td>(QP, 1.37)</td>\n",
              "      <td>(NP-TMP, 5.01)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(WHNP, 0.32)</td>\n",
              "      <td>(SBAR, 0.47)</td>\n",
              "      <td>(PRT, 0.34)</td>\n",
              "      <td>(INTJ, 1.43)</td>\n",
              "      <td>(WHNP, 0.17)</td>\n",
              "      <td>(PP, 0.42)</td>\n",
              "      <td>(QP, 3.95)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  aspect evaluation feature request  ... solution proposal          others\n",
              "0     (ADJP, 87.07)    (ADJP, 45.2)  ...      (NP, 106.08)     (NP, 112.1)\n",
              "1     (ADVP, 36.09)     (NP, 34.18)  ...       (PRT, 2.62)    (ADJP, 71.3)\n",
              "2     (SBAR, 18.83)      (QP, 3.19)  ...         (X, 1.55)    (INTJ, 5.56)\n",
              "3        (QP, 0.44)       (X, 0.89)  ...        (QP, 1.37)  (NP-TMP, 5.01)\n",
              "4      (WHNP, 0.32)    (SBAR, 0.47)  ...        (PP, 0.42)      (QP, 3.95)\n",
              "5                                  ...                                \n",
              "\n",
              "[6 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Mz3mv8Jcw_",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "07bb5739-147d-4b4e-b067-e9d123e65002"
      },
      "source": [
        "#@title correlations\n",
        "\n",
        "import joblib\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "#joblib.load(drive_folder\n",
        "tfidf_over_with = CalculateOverlap(words_by_tfidf_with, 100)\n",
        "tfidf_upper_with = [tfidf_over_with.iloc[ix,jx] for ix in range(tfidf_over_with.shape[0]) for jx in range(tfidf_over_with.shape[1]) if ix < jx]\n",
        "tfidf_over_wout = CalculateOverlap(words_by_tfidf_wout, 100)\n",
        "tfidf_upper_wout = [tfidf_over_wout.iloc[ix,jx] for ix in range(tfidf_over_wout.shape[0]) for jx in range(tfidf_over_wout.shape[1]) if ix < jx]\n",
        "inout_over_with = CalculateOverlap(words_by_zinout_with, 100)\n",
        "inout_upper_with = [inout_over_with.iloc[ix,jx] for ix in range(inout_over_with.shape[0]) for jx in range(inout_over_with.shape[1]) if ix < jx]\n",
        "inout_over_wout = CalculateOverlap(words_by_zinout_wout, 100)\n",
        "inout_upper_wout = [inout_over_wout.iloc[ix,jx] for ix in range(inout_over_wout.shape[0]) for jx in range(inout_over_wout.shape[1]) if ix < jx]\n",
        "\n",
        "print(\n",
        "  'Correlation between TFIDF w/out stopwords and InOut w/out stopwords: %.4f\\n' %  np.corrcoef(tfidf_upper_wout, inout_upper_wout)[0,1]\n",
        "  + 'Correlation between TFIDF w/out stopwords and Inout with stopwords: %.4f\\n' %  np.corrcoef(tfidf_upper_wout, inout_upper_with)[0,1]\n",
        ")\n",
        "\n",
        "joblib.dump({\n",
        "    'TFIDF overlap matrix w/ stopwords': tfidf_over_with, \n",
        "    'InOut overlap matrix w/ stopwords': inout_over_with,\n",
        "    'TFIDF overlap matrix w/out stopwords': tfidf_over_wout, \n",
        "    'InOut overlap matrix w/out stopwords': inout_over_wout\n",
        "}, os.path.join(drive_folder, \"out\", \"tfidf_inout_overlap.joblib\"))\n",
        "\n",
        "# mat = [0.92, 0.918, 0.922, 0.878, 0.818, 0.896, 0.838, 0.842, 0.764, 0.776, 0.826, 0.87, 0.91, 0.86, 0.814, 0.886, 0.848, 0.858, 0.786, 0.854, 0.786]\n",
        "# print(tfidf_upper_wout, '\\n', inout_upper_wout, '\\n', mat)\n",
        "# print(np.corrcoef(tfidf_upper_wout, mat))\n",
        "# print(np.corrcoef(inout_upper_wout, mat))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Correlation between TFIDF w/out stopwords and InOut w/out stopwords: 0.4593\n",
            "Correlation between TFIDF w/out stopwords and Inout with stopwords: 0.2316\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/gdrive/My Drive/COMP762_IntentionMining/out/tfidf_inout_overlap.joblib']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WnAN1xg6XogM"
      },
      "source": [
        "The results presented above suggest that TFIDF without stopwords and InOut with stopwords measure different things (or, at least, more different than without and without). Important question: what are the ranks of stopwords in InOut? If the ranks are high, it may be necessary to remove stopwords from both InOut and."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMx5NnzHYSE8",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "outputId": "a087c1cc-98fb-4e8f-f849-78b210997e77"
      },
      "source": [
        "#@title Proportion of TFIDF and InOut top-100 words which are stopwords\n",
        "\n",
        "tfidf_by_cat = words_by_tfidf_with[:100].applymap(lambda x: 1 if str(x) in stopwords.words('english') else 0).sum()\n",
        "tfidf_by_cat = tfidf_by_cat.to_numpy()/100\n",
        "tfidf_by_cat = np.append(tfidf_by_cat, tfidf_by_cat.sum() / tfidf_by_cat.size)\n",
        "\n",
        "inout_by_cat = words_by_zinout_with[:100].applymap(lambda x: 1 if str(x) in stopwords.words('english') else 0).sum()\n",
        "inout_by_cat = inout_by_cat.to_numpy()/100\n",
        "inout_by_cat = np.append(inout_by_cat, inout_by_cat.sum() / inout_by_cat.size)\n",
        "\n",
        "columns = list(words_by_zinout_with.columns)\n",
        "columns.append(\"\\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b \\u200b overall\")\n",
        "prop = pd.DataFrame(np.stack((tfidf_by_cat, inout_by_cat)), index=(\"TFIDF\", \"InOut\"), columns=columns)\n",
        "display(prop)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aspect evaluation</th>\n",
              "      <th>feature request</th>\n",
              "      <th>information giving</th>\n",
              "      <th>information seeking</th>\n",
              "      <th>problem discovery</th>\n",
              "      <th>solution proposal</th>\n",
              "      <th>others</th>\n",
              "      <th>        overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>TFIDF</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.44</td>\n",
              "      <td>0.49</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.45</td>\n",
              "      <td>0.34</td>\n",
              "      <td>0.451429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>InOut</th>\n",
              "      <td>0.18</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.30</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.16</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.11</td>\n",
              "      <td>0.187143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       aspect evaluation  feature request  ...  others          overall\n",
              "TFIDF               0.50             0.44  ...    0.34                 0.451429\n",
              "InOut               0.18             0.14  ...    0.11                 0.187143\n",
              "\n",
              "[2 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dL9AHpczlpCp"
      },
      "source": [
        "Conclusion: the proportion of stopwords in TFIDF (~45%) is more than sufficient to justify ysing TFIDF without stopwords. For InOut, it is sufficiently high (19%) to consider the analysis without stopwords as well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjR21SSgFJTL"
      },
      "source": [
        "# Garbage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw2mzWVGK7e2",
        "cellView": "form"
      },
      "source": [
        "# @title \n",
        "# title Download datasets from Google Drive, and define Sentence, Token, GetAllText() and GetTextByCategories() {display-mode: \"form\"}\n",
        "\n",
        "# import os\n",
        "# import gdown\n",
        "# import json\n",
        "# import re\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# class Token:\n",
        "#   def __init__(self, default_format, properties):\n",
        "#     if not callable(default_format):\n",
        "#       self.default_format = lambda: default_format\n",
        "#     else:\n",
        "#       self.default_format = default_format\n",
        "#     self.properties = {**properties}\n",
        "  \n",
        "#   def __getitem__(self, ix):\n",
        "#     return self.properties.__getitem__(ix)\n",
        "\n",
        "#   def __setitem__(self, ix, val):\n",
        "#     return self.properties.__setitem__(ix, val)\n",
        "\n",
        "#   def to_string(self, format_):\n",
        "#     return format_.format(**self.properties)\n",
        "\n",
        "#   def __string_rep(self):\n",
        "#     return self.to_string(self.default_format())\n",
        "\n",
        "#   def __str__(self):\n",
        "#     return self.__string_rep()\n",
        "  \n",
        "#   def __repr__(self):\n",
        "#     return self.__str__() + \": \" + self.properties.__repr__()\n",
        "\n",
        "#   def __hash__(self):\n",
        "#     return self.__string_rep().__hash__()\n",
        "\n",
        "#   def __eq__(self, other):\n",
        "#     return self.__string_rep() == other.__string_rep()\n",
        "  \n",
        "#   def __gt__(self, other):\n",
        "#     return self.__string_rep() > other.__string_rep()\n",
        "    \n",
        "#   def __lt__(self, other):\n",
        "#     return self.__string_rep() < other.__string_rep()\n",
        "\n",
        "\n",
        "# class Sentence:\n",
        "#   def __init__(self, json_, fmt, get_ancestor):\n",
        "#     self.json = {**json_}\n",
        "#     self.fmt = fmt\n",
        "#     # Lowercase lemmata (plural of lemma)\n",
        "#     for t in self.json['tokens']:\n",
        "#       t['lemma'] = t['lemma'].lower()\n",
        "#     # Create tokens\n",
        "#     self.tokens = \\\n",
        "#     [\n",
        "#       Token(self.getFormat, token) \n",
        "#       for token in self.json['tokens']\n",
        "#     ]\n",
        "#     # Find each token's ancestor\n",
        "#     if get_ancestor:\n",
        "#       tree = self.makeParseTree()\n",
        "#       for ix, token in enumerate(self.tokens):\n",
        "#         tree_ix = tree.leaf_treeposition(ix)\n",
        "#         token[\"ancestor\"] = tree[tree_ix[:-2]].label()\n",
        "  \n",
        "#   def __getitem__(self, ix):\n",
        "#     return self.tokens[ix]\n",
        "  \n",
        "#   def __setitem__(self, ix, val):\n",
        "#     self.tokens[ix] = val\n",
        "\n",
        "#   def getFormat(self):\n",
        "#     return self.fmt\n",
        "  \n",
        "#   def setFormat(self, newFmt):\n",
        "#     self.fmt = newFmt\n",
        "  \n",
        "#   def withoutPunctuation(self):\n",
        "#     without = Sentence({**self.json}, self.getFormat(), False)\n",
        "#     # Remove punctuation from parse\n",
        "#     parse = self.json[\"parse\"]\n",
        "#     punct_ix = list(re.finditer(\"\\([^a-zA-Z0-9(]\\S* \\S*[^a-zA-Z0-9)]\\)\", parse))\n",
        "#     for m in reversed(punct_ix):\n",
        "#       parse = parse[:m.start()]+ parse[m.end():]\n",
        "#     without.json[\"parse\"] = parse\n",
        "#     # Remove punctuation from tokens\n",
        "#     tokens = []\n",
        "#     for ix, t in enumerate(self.tokens):\n",
        "#       if t[\"pos\"][0].isalpha():\n",
        "#         tokens.append(Token(without.getFormat, {**t.properties}))\n",
        "#       elif 0 < len(tokens):\n",
        "#         tokens[-1][\"after\"] += t[\"after\"]\n",
        "#     without.tokens = tokens\n",
        "#     # Done, leave the other fields untouched\n",
        "#     return without\n",
        "\n",
        "#   def withoutStopWords(self):\n",
        "#     without = Sentence(self.json, self.getFormat(), False)\n",
        "#     # Remove stopwords from tokens\n",
        "#     tokens = []\n",
        "#     for ix, t in enumerate(self.tokens):\n",
        "#       if t[\"lemma\"].lower() not in stopwords.words('english'):\n",
        "#         tokens.append(Token(without.getFormat, {**t.properties}))\n",
        "#     without.tokens = tokens\n",
        "#     # Done, leave the other fields untouched\n",
        "#     return without\n",
        "\n",
        "#   def makeParseTree(self):\n",
        "#     from nltk.tree import Tree\n",
        "#     parse = self.json['parse']\n",
        "#     # Replace words with indices in parse string\n",
        "#     indices = list(enumerate(re.finditer('\\s[^ )]+\\)', parse)))\n",
        "#     for ix, match in reversed(indices):\n",
        "#       parse = parse[:match.start() + 1] + str(ix) + parse[match.end()-1:]\n",
        "#     # Use parse string to create a tree\n",
        "#     tree = Tree.fromstring(parse)\n",
        "#     # Replace indices in tree with tokens\n",
        "#     for lix, leaf in enumerate([leaf for leaf in tree.leaves() if leaf.isnumeric()]):\n",
        "#       tree[tree.leaf_treeposition(lix)] = self.tokens[int(leaf)]\n",
        "#     return tree\n",
        "  \n",
        "#   def to_string(self, fmt=None, after=None):\n",
        "#     if fmt is None:\n",
        "#       fmt = self.fmt\n",
        "#     out = ''\n",
        "#     for t in self.tokens:\n",
        "#       out += t.to_string(fmt) + (t[\"after\"] if after is None else after)\n",
        "#     return out\n",
        "\n",
        "#   def __str__(self):\n",
        "#     return self.to_string()\n",
        "  \n",
        "#   def __repr__(self):\n",
        "#     return self.__str__().strip() + \": \" + repr(self.json)\n",
        "  \n",
        "#   def __len__(self):\n",
        "#     return len(self.tokens)\n",
        "\n",
        "#   @staticmethod\n",
        "#   def __findLabelInTree(tree, label):\n",
        "#     return [p for p in tree.treepositions() if isinstance(tree[p], nltk.tree.Tree) and label == tree[p].label()]\n",
        "  \n",
        "#   @staticmethod\n",
        "#   def __getParseStringFromTreeWithTokens(tree):\n",
        "#     tree_copy = tree.copy(deep=True)\n",
        "#     for lix in range(len(tree_copy.leaves())):\n",
        "#       tree_copy[tree_copy.leaf_treeposition(lix)] = \\\n",
        "#         tree_copy[tree_copy.leaf_treeposition(lix)].to_string(\"{originalText}\")\n",
        "#     return str(tree_copy)\n",
        "  \n",
        "#   @staticmethod\n",
        "#   def __treeToSentence(tree, fmt):\n",
        "#     return Sentence(\n",
        "#       {\n",
        "#         \"parse\": Sentence.__getParseStringFromTreeWithTokens(tree),\n",
        "#         \"tokens\": [token.properties for token in tree.leaves()]\n",
        "#       },\n",
        "#       fmt, False\n",
        "#     )\n",
        "  \n",
        "#   @staticmethod\n",
        "#   def SwapPhrases(sentence_1, sentence_2, label, validate_phrase=None, prefix=None, suffix=None):\n",
        "#     import numpy\n",
        "    \n",
        "#     # Build a tree from each sentence\n",
        "#     tree_1 = sentence_1.makeParseTree()\n",
        "#     tree_2 = sentence_2.makeParseTree()\n",
        "#     # Find phrase in both trees\n",
        "#     tree_1_phrases = Sentence.__findLabelInTree(tree_1, label)\n",
        "#     tree_2_phrases = Sentence.__findLabelInTree(tree_2, label)\n",
        "#     # If there is nothing to swap, return\n",
        "#     if 0 == len(tree_1_phrases) or 0 == len(tree_2_phrases):\n",
        "#       return (None, None)\n",
        "#     # Pick a phrase at random from each sentence\n",
        "#     tree_1_index = tree_1_phrases[np.random.randint(len(tree_1_phrases))]\n",
        "#     tree_2_index = tree_2_phrases[np.random.randint(len(tree_2_phrases))]\n",
        "#     # Validate the phrases to swap\n",
        "#     if validate_phrase is not None \\\n",
        "#       and not validate_phrase(tree_1, tree_1_index, tree_2, tree_2_index):\n",
        "#         return (None, None)\n",
        "#     # DEBUG #\n",
        "#     if prefix is not None:\n",
        "#       if isinstance(prefix, str):\n",
        "#         pprefix = [prefix, prefix]\n",
        "#       ttt = tree_1[tree_1_index].leaves()[0]\n",
        "#       tok_1_index = tree_1[tree_1_index].leaf_treeposition(0)\n",
        "#       tree_1[tree_1_index][tok_1_index] = Token(\n",
        "#           tree_1[tree_1_index][tok_1_index].default_format,\n",
        "#           tree_1[tree_1_index][tok_1_index].properties\n",
        "#       )\n",
        "#       tok_2_index = tree_2[tree_2_index].leaf_treeposition(0)\n",
        "#       tree_2[tree_2_index][tok_2_index] = Token(\n",
        "#           tree_2[tree_2_index][tok_2_index].default_format,\n",
        "#           tree_2[tree_2_index][tok_2_index].properties\n",
        "#       )\n",
        "#       keys = [\"originalText\", \"lemma\"]\n",
        "#       for k in keys:\n",
        "#         tree_1[tree_1_index].leaves()[0][k] = \\\n",
        "#           prefix[0] + tree_1[tree_1_index][tok_1_index][k]\n",
        "#         tree_2[tree_2_index].leaves()[0][k] = \\\n",
        "#           prefix[1] + tree_2[tree_2_index][tok_2_index][k]\n",
        "#     if suffix is not None:\n",
        "#       if isinstance(suffix, str):\n",
        "#         suffix = [suffix, suffix]\n",
        "#       tok_1_index = tree_1[tree_1_index].leaf_treeposition(len(tree_1[tree_1_index].leaves())-1)\n",
        "#       tree_1[tree_1_index][tok_1_index] = Token(\n",
        "#           tree_1[tree_1_index][tok_1_index].default_format,\n",
        "#           tree_1[tree_1_index][tok_1_index].properties\n",
        "#       )\n",
        "#       tok_2_index = tree_2[tree_2_index].leaf_treeposition(len(tree_2[tree_2_index].leaves())-1)\n",
        "#       tree_2[tree_2_index][tok_2_index] = Token(\n",
        "#           tree_2[tree_2_index][tok_2_index].default_format,\n",
        "#           tree_2[tree_2_index][tok_2_index].properties\n",
        "#       )\n",
        "#       keys = [\"originalText\", \"lemma\"]\n",
        "#       for k in keys:\n",
        "#         tree_1[tree_1_index].leaves()[-1][k] = \\\n",
        "#           tree_1[tree_1_index][tok_1_index][k] + suffix[0]\n",
        "#         tree_2[tree_2_index].leaves()[-1][k] = \\\n",
        "#           tree_2[tree_2_index][tok_2_index][k] + suffix[1]\n",
        "#     #########\n",
        "#     # Swap\n",
        "#     swap = tree_1[tree_1_index]\n",
        "#     tree_1[tree_1_index] = tree_2[tree_2_index]\n",
        "#     tree_2[tree_2_index] = swap\n",
        "#     # Create Sentences\n",
        "#     #   Create copy, convert leaves to strings (lemma), and get parse string\n",
        "#     return \\\n",
        "#     (\n",
        "#       Sentence.__treeToSentence(tree_1, sentence_1.fmt),\n",
        "#       Sentence.__treeToSentence(tree_2, sentence_2.fmt)\n",
        "#     )\n",
        "\n",
        "\n",
        "# archive = \"Automating-Intention-Mining-parsed-data.tar.gz\"\n",
        "# url = \"https://drive.google.com/uc?id=1MYR04EN9wyEw5C-RhpAmX5Xnat-jiBSy\"\n",
        "# print(\"Downloading {}: \".format(archive), end=\"\")\n",
        "# if not os.path.isfile(archive):\n",
        "#   gdown.download(url, archive, 0)\n",
        "# else:\n",
        "#   print('file already exists. Skipping download.')\n",
        "# print(\"done\")\n",
        "\n",
        "# # Remove old paths\n",
        "# parsed_folder = 'parsed'\n",
        "# if os.path.exists(parsed_folder):\n",
        "#   !rm -r parsed\n",
        "\n",
        "# print(\"Extracting files... \")\n",
        "# !tar xvf Automating-Intention-Mining-parsed-data.tar.gz\n",
        "# print(\"Extracting files... done\")\n",
        "\n",
        "# # Load data\n",
        "# projects = ['DECA', 'bootstrap', 'docker', 'tensorflow', 'vscode']\n",
        "# categories = [\n",
        "#   'aspect evaluation', 'feature request', 'information giving',\n",
        "#   'information seeking', 'problem discovery', 'solution proposal', 'others'\n",
        "# ]\n",
        "\n",
        "# _parsed_cat_proj = {}\n",
        "# for c in categories:\n",
        "#   _parsed_cat_proj[c] = {}\n",
        "#   for p in projects:\n",
        "#     with open(os.path.join(parsed_folder, p, c + \".json\"), 'r', encoding='latin-1') \\\n",
        "#       as f:\n",
        "#       j = json.load(f)\n",
        "#       assert c == j[\"docId\"]\n",
        "#       _parsed_cat_proj[c][p] = j[\"sentences\"]\n",
        "#       # for s in j[\"sentences\"]:\n",
        "#       #   _parsed_cat_proj[c][p].append(Sentence(s, \"{lemma}/{pos}\"))\n",
        "\n",
        "# def GetAllText(\n",
        "#   word=\"word\", show_pos=False, remove_punctuation=False, remove_stopwords=False,\n",
        "#   get_ancestors=True, projects_to_exclude=None\n",
        "# ):\n",
        "\n",
        "#   if word == \"word\":\n",
        "#     fmt = \"{originalText}\"\n",
        "#   elif word == \"lemma\":\n",
        "#     fmt = \"{lemma}\"\n",
        "#   else:\n",
        "#     raise Exception(\"Value (\\\"{}\\\") for @word not recognized.\")\n",
        "#   if show_pos:\n",
        "#     fmt += \"/{pos}\"\n",
        "\n",
        "#   if remove_stopwords:\n",
        "#     constructor1 = lambda *args: Sentence(*args).withoutStopWords()\n",
        "#   else:\n",
        "#     constructor1 = lambda *args: Sentence(*args)\n",
        "\n",
        "#   if remove_punctuation:\n",
        "#     constructor2 = lambda *args: constructor1(*args).withoutPunctuation()\n",
        "#   else:\n",
        "#     constructor2 = constructor1\n",
        "\n",
        "#   if projects_to_exclude is None:\n",
        "#     projects_to_exclude = []\n",
        "#   elif isinstance(projects_to_exclude, str):\n",
        "#     projects_to_exclude = [projects_to_exclude]\n",
        "\n",
        "#   projects_to_exclude = [p.lower() for p in projects_to_exclude]\n",
        "\n",
        "#   return \\\n",
        "#   [\n",
        "#     constructor2(sentence, fmt, get_ancestors)\n",
        "#     for category_name, projects in _parsed_cat_proj.items()\n",
        "#     for project_name, project_text in projects.items()\n",
        "#     for sentence in project_text\n",
        "#     if project_name.lower() not in projects_to_exclude\n",
        "#   ]\n",
        "\n",
        "\n",
        "# def GetTextByCategories(\n",
        "#   word=\"word\", show_pos=False, remove_punctuation=False, remove_stopwords=False,\n",
        "#   get_ancestors=True, projects_to_exclude=None\n",
        "# ):\n",
        "\n",
        "#   if word == \"word\":\n",
        "#     fmt = \"{originalText}\"\n",
        "#   elif word == \"lemma\":\n",
        "#     fmt = \"{lemma}\"\n",
        "#   else:\n",
        "#     raise Exception(\"Value (\\\"{}\\\") for @word not recognized.\")\n",
        "#   if show_pos:\n",
        "#     fmt += \"/{pos}\"\n",
        "\n",
        "#   if remove_stopwords:\n",
        "#     constructor1 = lambda *args: Sentence(*args).withoutStopWords()\n",
        "#   else:\n",
        "#     constructor1 = lambda *args: Sentence(*args)\n",
        "\n",
        "#   if remove_punctuation:\n",
        "#     constructor2 = lambda *args: constructor1(*args).withoutPunctuation()\n",
        "#   else:\n",
        "#     constructor2 = constructor1\n",
        "\n",
        "#   if projects_to_exclude is None:\n",
        "#     projects_to_exclude = []\n",
        "#   elif isinstance(projects_to_exclude, str):\n",
        "#     projects_to_exclude = [projects_to_exclude]\n",
        "\n",
        "#   projects_to_exclude = [p.lower() for p in projects_to_exclude]\n",
        "\n",
        "#   return \\\n",
        "#   {\n",
        "#     category_name:\n",
        "#     [\n",
        "#       constructor2(sentence, fmt, get_ancestors)\n",
        "#       for project_name, project_text in projects.items()\n",
        "#       for sentence in project_text\n",
        "#       if project_name.lower() not in projects_to_exclude\n",
        "#     ]\n",
        "#     for category_name, projects in _parsed_cat_proj.items()\n",
        "#   }\n",
        "\n",
        "\n",
        "# print(\n",
        "#   '\\n\\n=======================================\\n'\n",
        "#   + 'Use GetAllText() to get all text as a list.\\n'\n",
        "#   + 'Use GetTextByCategories() to get a dictionary with category names as\\n'\n",
        "#   + '  keys and lists of sentences belonging to that category as values.\\n'\n",
        "#   + '=======================================\\n'\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY3JI74eV5Rw",
        "cellView": "form"
      },
      "source": [
        "# @title\n",
        "# title Download datasets from Google Drive, and define Sentence, Token, GetAllText() and GetTextByCategories() {display-mode: \"form\"}\n",
        "\n",
        "# import os\n",
        "# import gdown\n",
        "# import json\n",
        "# import re\n",
        "# import nltk\n",
        "# nltk.download('stopwords')\n",
        "\n",
        "# class Token:\n",
        "#   def __init__(self, default_format, properties):\n",
        "#     if not callable(default_format):\n",
        "#       self.default_format = lambda: default_format\n",
        "#     else:\n",
        "#       self.default_format = default_format\n",
        "#     self.properties = {**properties}\n",
        "  \n",
        "#   def __getitem__(self, ix):\n",
        "#     return self.properties.__getitem__(ix)\n",
        "\n",
        "#   def __setitem__(self, ix, val):\n",
        "#     return self.properties.__setitem__(ix, val)\n",
        "\n",
        "#   def to_string(self, format_):\n",
        "#     return format_.format(**self.properties)\n",
        "\n",
        "#   def __string_rep(self):\n",
        "#     return self.to_string(self.default_format())\n",
        "\n",
        "#   def __str__(self):\n",
        "#     return self.__string_rep()\n",
        "  \n",
        "#   def __repr__(self):\n",
        "#     return self.__str__() + \": \" + self.properties.__repr__()\n",
        "\n",
        "#   def __hash__(self):\n",
        "#     return self.__string_rep().__hash__()\n",
        "\n",
        "#   def __eq__(self, other):\n",
        "#     return self.__string_rep() == other.__string_rep()\n",
        "  \n",
        "#   def __gt__(self, other):\n",
        "#     return self.__string_rep() > other.__string_rep()\n",
        "    \n",
        "#   def __lt__(self, other):\n",
        "#     return self.__string_rep() < other.__string_rep()\n",
        "\n",
        "\n",
        "# class Sentence:\n",
        "#   def __init__(self, json_, fmt, get_ancestor):\n",
        "#     self.json = {**json_}\n",
        "#     self.fmt = fmt\n",
        "#     # Lowercase lemmata (plural of lemma)\n",
        "#     for t in self.json['tokens']:\n",
        "#       t['lemma'] = t['lemma'].lower()\n",
        "#     # Create tokens\n",
        "#     self.tokens = \\\n",
        "#     [\n",
        "#       Token(self.getFormat, token) \n",
        "#       for token in self.json['tokens']\n",
        "#     ]\n",
        "#     # Find each token's ancestor\n",
        "#     if get_ancestor:\n",
        "#       tree = self.makeParseTree()\n",
        "#       for ix, token in enumerate(self.tokens):\n",
        "#         tree_ix = tree.leaf_treeposition(ix)\n",
        "#         token[\"ancestor\"] = tree[tree_ix[:-2]].label()\n",
        "  \n",
        "#   def __getitem__(self, ix):\n",
        "#     return self.tokens[ix]\n",
        "  \n",
        "#   def __setitem__(self, ix, val):\n",
        "#     self.tokens[ix] = val\n",
        "\n",
        "#   def getFormat(self):\n",
        "#     return self.fmt\n",
        "  \n",
        "#   def setFormat(self, newFmt):\n",
        "#     self.fmt = newFmt\n",
        "  \n",
        "#   def withoutPunctuation(self):\n",
        "#     without = Sentence({**self.json}, self.getFormat(), False)\n",
        "#     # Remove punctuation from parse\n",
        "#     parse = self.json[\"parse\"]\n",
        "#     punct_ix = list(re.finditer(\"\\([^a-zA-Z0-9(]\\S* \\S*[^a-zA-Z0-9)]\\)\", parse))\n",
        "#     for m in reversed(punct_ix):\n",
        "#       parse = parse[:m.start()]+ parse[m.end():]\n",
        "#     without.json[\"parse\"] = parse\n",
        "#     # Remove punctuation from tokens\n",
        "#     tokens = []\n",
        "#     for ix, t in enumerate(self.tokens):\n",
        "#       if t[\"pos\"][0].isalpha():\n",
        "#         tokens.append(Token(without.getFormat, {**t.properties}))\n",
        "#       elif 0 < len(tokens):\n",
        "#         tokens[-1][\"after\"] += t[\"after\"]\n",
        "#     without.tokens = tokens\n",
        "#     # Done, leave the other fields untouched\n",
        "#     return without\n",
        "\n",
        "#   def withoutStopWords(self):\n",
        "#     without = Sentence(self.json, self.getFormat(), False)\n",
        "#     # Remove stopwords from tokens\n",
        "#     tokens = []\n",
        "#     for ix, t in enumerate(self.tokens):\n",
        "#       if t[\"lemma\"].lower() not in stopwords.words('english'):\n",
        "#         tokens.append(Token(without.getFormat, {**t.properties}))\n",
        "#     without.tokens = tokens\n",
        "#     # Done, leave the other fields untouched\n",
        "#     return without\n",
        "\n",
        "#   def makeParseTree(self):\n",
        "#     from nltk.tree import Tree\n",
        "#     parse = self.json['parse']\n",
        "#     # Replace words with indices in parse string\n",
        "#     indices = list(enumerate(re.finditer('\\s[^ )]+\\)', parse)))\n",
        "#     for ix, match in reversed(indices):\n",
        "#       parse = parse[:match.start() + 1] + str(ix) + parse[match.end()-1:]\n",
        "#     # Use parse string to create a tree\n",
        "#     tree = Tree.fromstring(parse)\n",
        "#     # Replace indices in tree with tokens\n",
        "#     for lix, leaf in enumerate([leaf for leaf in tree.leaves() if leaf.isnumeric()]):\n",
        "#       tree[tree.leaf_treeposition(lix)] = self.tokens[int(leaf)]\n",
        "#     return tree\n",
        "  \n",
        "#   def to_string(self, fmt=None, after=None):\n",
        "#     if fmt is None:\n",
        "#       fmt = self.fmt\n",
        "#     out = ''\n",
        "#     for t in self.tokens:\n",
        "#       out += t.to_string(fmt) + (t[\"after\"] if after is None else after)\n",
        "#     return out\n",
        "\n",
        "#   def __str__(self):\n",
        "#     return self.to_string()\n",
        "  \n",
        "#   def __repr__(self):\n",
        "#     return self.__str__().strip() + \": \" + repr(self.json)\n",
        "  \n",
        "#   def __len__(self):\n",
        "#     return len(self.tokens)\n",
        "\n",
        "#   @staticmethod\n",
        "#   def __findLabelInTree(tree, label):\n",
        "#     return [p for p in tree.treepositions() if isinstance(tree[p], nltk.tree.Tree) and label == tree[p].label()]\n",
        "  \n",
        "#   @staticmethod\n",
        "#   def __getParseStringFromTreeWithTokens(tree):\n",
        "#     tree_copy = tree.copy(deep=True)\n",
        "#     for lix in range(len(tree_copy.leaves())):\n",
        "#       tree_copy[tree_copy.leaf_treeposition(lix)] = \\\n",
        "#         tree_copy[tree_copy.leaf_treeposition(lix)].to_string(\"{originalText}\")\n",
        "#     return str(tree_copy)\n",
        "  \n",
        "#   @staticmethod\n",
        "#   def __treeToSentence(tree, fmt):\n",
        "#     return Sentence(\n",
        "#       {\n",
        "#         \"parse\": Sentence.__getParseStringFromTreeWithTokens(tree),\n",
        "#         \"tokens\": [token.properties for token in tree.leaves()]\n",
        "#       },\n",
        "#       fmt, False\n",
        "#     )\n",
        "  \n",
        "#   @staticmethod\n",
        "#   def SwapPhrases(sentence_1, sentence_2, label, validate_phrase=None, prefix=None, suffix=None):\n",
        "#     import numpy\n",
        "    \n",
        "#     # Build a tree from each sentence\n",
        "#     tree_1 = sentence_1.makeParseTree()\n",
        "#     tree_2 = sentence_2.makeParseTree()\n",
        "#     # Find phrase in both trees\n",
        "#     tree_1_phrases = Sentence.__findLabelInTree(tree_1, label)\n",
        "#     tree_2_phrases = Sentence.__findLabelInTree(tree_2, label)\n",
        "#     # If there is nothing to swap, return\n",
        "#     if 0 == len(tree_1_phrases) or 0 == len(tree_2_phrases):\n",
        "#       return (None, None)\n",
        "#     # Pick a phrase at random from each sentence\n",
        "#     tree_1_index = tree_1_phrases[np.random.randint(len(tree_1_phrases))]\n",
        "#     tree_2_index = tree_2_phrases[np.random.randint(len(tree_2_phrases))]\n",
        "#     # Validate the phrases to swap\n",
        "#     if validate_phrase is not None \\\n",
        "#       and not validate_phrase(tree_1, tree_1_index, tree_2, tree_2_index):\n",
        "#         return (None, None)\n",
        "#     # DEBUG #\n",
        "#     if prefix is not None:\n",
        "#       if isinstance(prefix, str):\n",
        "#         pprefix = [prefix, prefix]\n",
        "#       ttt = tree_1[tree_1_index].leaves()[0]\n",
        "#       tok_1_index = tree_1[tree_1_index].leaf_treeposition(0)\n",
        "#       tree_1[tree_1_index][tok_1_index] = Token(\n",
        "#           tree_1[tree_1_index][tok_1_index].default_format,\n",
        "#           tree_1[tree_1_index][tok_1_index].properties\n",
        "#       )\n",
        "#       tok_2_index = tree_2[tree_2_index].leaf_treeposition(0)\n",
        "#       tree_2[tree_2_index][tok_2_index] = Token(\n",
        "#           tree_2[tree_2_index][tok_2_index].default_format,\n",
        "#           tree_2[tree_2_index][tok_2_index].properties\n",
        "#       )\n",
        "#       keys = [\"originalText\", \"lemma\"]\n",
        "#       for k in keys:\n",
        "#         tree_1[tree_1_index].leaves()[0][k] = \\\n",
        "#           prefix[0] + tree_1[tree_1_index][tok_1_index][k]\n",
        "#         tree_2[tree_2_index].leaves()[0][k] = \\\n",
        "#           prefix[1] + tree_2[tree_2_index][tok_2_index][k]\n",
        "#     if suffix is not None:\n",
        "#       if isinstance(suffix, str):\n",
        "#         suffix = [suffix, suffix]\n",
        "#       tok_1_index = tree_1[tree_1_index].leaf_treeposition(len(tree_1[tree_1_index].leaves())-1)\n",
        "#       tree_1[tree_1_index][tok_1_index] = Token(\n",
        "#           tree_1[tree_1_index][tok_1_index].default_format,\n",
        "#           tree_1[tree_1_index][tok_1_index].properties\n",
        "#       )\n",
        "#       tok_2_index = tree_2[tree_2_index].leaf_treeposition(len(tree_2[tree_2_index].leaves())-1)\n",
        "#       tree_2[tree_2_index][tok_2_index] = Token(\n",
        "#           tree_2[tree_2_index][tok_2_index].default_format,\n",
        "#           tree_2[tree_2_index][tok_2_index].properties\n",
        "#       )\n",
        "#       keys = [\"originalText\", \"lemma\"]\n",
        "#       for k in keys:\n",
        "#         tree_1[tree_1_index].leaves()[-1][k] = \\\n",
        "#           tree_1[tree_1_index][tok_1_index][k] + suffix[0]\n",
        "#         tree_2[tree_2_index].leaves()[-1][k] = \\\n",
        "#           tree_2[tree_2_index][tok_2_index][k] + suffix[1]\n",
        "#     #########\n",
        "#     # Swap\n",
        "#     swap = tree_1[tree_1_index]\n",
        "#     tree_1[tree_1_index] = tree_2[tree_2_index]\n",
        "#     tree_2[tree_2_index] = swap\n",
        "#     # Create Sentences\n",
        "#     #   Create copy, convert leaves to strings (lemma), and get parse string\n",
        "#     return \\\n",
        "#     (\n",
        "#       Sentence.__treeToSentence(tree_1, sentence_1.fmt),\n",
        "#       Sentence.__treeToSentence(tree_2, sentence_2.fmt)\n",
        "#     )\n",
        "\n",
        "\n",
        "# archive = \"Automating-Intention-Mining-parsed-data.tar.gz\"\n",
        "# url = \"https://drive.google.com/uc?id=1MYR04EN9wyEw5C-RhpAmX5Xnat-jiBSy\"\n",
        "# print(\"Downloading {}: \".format(archive), end=\"\")\n",
        "# if not os.path.isfile(archive):\n",
        "#   gdown.download(url, archive, 0)\n",
        "# else:\n",
        "#   print('file already exists. Skipping download.')\n",
        "# print(\"done\")\n",
        "\n",
        "# # Remove old paths\n",
        "# parsed_folder = 'parsed'\n",
        "# if os.path.exists(parsed_folder):\n",
        "#   !rm -r parsed\n",
        "\n",
        "# print(\"Extracting files... \")\n",
        "# !tar xvf Automating-Intention-Mining-parsed-data.tar.gz\n",
        "# print(\"Extracting files... done\")\n",
        "\n",
        "# # Load data\n",
        "# projects = ['DECA', 'bootstrap', 'docker', 'tensorflow', 'vscode']\n",
        "# categories = [\n",
        "#   'aspect evaluation', 'feature request', 'information giving',\n",
        "#   'information seeking', 'problem discovery', 'solution proposal', 'others'\n",
        "# ]\n",
        "\n",
        "# _parsed_cat_proj = {}\n",
        "# for c in categories:\n",
        "#   _parsed_cat_proj[c] = {}\n",
        "#   for p in projects:\n",
        "#     with open(os.path.join(parsed_folder, p, c + \".json\"), 'r', encoding='latin-1') \\\n",
        "#       as f:\n",
        "#       j = json.load(f)\n",
        "#       assert c == j[\"docId\"]\n",
        "#       _parsed_cat_proj[c][p] = j[\"sentences\"]\n",
        "#       # for s in j[\"sentences\"]:\n",
        "#       #   _parsed_cat_proj[c][p].append(Sentence(s, \"{lemma}/{pos}\"))\n",
        "\n",
        "# def GetAllText(\n",
        "#   word=\"word\", show_pos=False, remove_punctuation=False, remove_stopwords=False,\n",
        "#   get_ancestors=True, projects_to_exclude=None\n",
        "# ):\n",
        "\n",
        "#   if word == \"word\":\n",
        "#     fmt = \"{originalText}\"\n",
        "#   elif word == \"lemma\":\n",
        "#     fmt = \"{lemma}\"\n",
        "#   else:\n",
        "#     raise Exception(\"Value (\\\"{}\\\") for @word not recognized.\")\n",
        "#   if show_pos:\n",
        "#     fmt += \"/{pos}\"\n",
        "\n",
        "#   if remove_stopwords:\n",
        "#     constructor1 = lambda *args: Sentence(*args).withoutStopWords()\n",
        "#   else:\n",
        "#     constructor1 = lambda *args: Sentence(*args)\n",
        "\n",
        "#   if remove_punctuation:\n",
        "#     constructor2 = lambda *args: constructor1(*args).withoutPunctuation()\n",
        "#   else:\n",
        "#     constructor2 = constructor1\n",
        "\n",
        "#   if projects_to_exclude is None:\n",
        "#     projects_to_exclude = []\n",
        "#   elif isinstance(projects_to_exclude, str):\n",
        "#     projects_to_exclude = [projects_to_exclude]\n",
        "\n",
        "#   projects_to_exclude = [p.lower() for p in projects_to_exclude]\n",
        "\n",
        "#   return \\\n",
        "#   [\n",
        "#     constructor2(sentence, fmt, get_ancestors)\n",
        "#     for category_name, projects in _parsed_cat_proj.items()\n",
        "#     for project_name, project_text in projects.items()\n",
        "#     for sentence in project_text\n",
        "#     if project_name.lower() not in projects_to_exclude\n",
        "#   ]\n",
        "\n",
        "\n",
        "# def GetTextByCategories(\n",
        "#   word=\"word\", show_pos=False, remove_punctuation=False, remove_stopwords=False,\n",
        "#   get_ancestors=True, projects_to_exclude=None\n",
        "# ):\n",
        "\n",
        "#   if word == \"word\":\n",
        "#     fmt = \"{originalText}\"\n",
        "#   elif word == \"lemma\":\n",
        "#     fmt = \"{lemma}\"\n",
        "#   else:\n",
        "#     raise Exception(\"Value (\\\"{}\\\") for @word not recognized.\")\n",
        "#   if show_pos:\n",
        "#     fmt += \"/{pos}\"\n",
        "\n",
        "#   if remove_stopwords:\n",
        "#     constructor1 = lambda *args: Sentence(*args).withoutStopWords()\n",
        "#   else:\n",
        "#     constructor1 = lambda *args: Sentence(*args)\n",
        "\n",
        "#   if remove_punctuation:\n",
        "#     constructor2 = lambda *args: constructor1(*args).withoutPunctuation()\n",
        "#   else:\n",
        "#     constructor2 = constructor1\n",
        "\n",
        "#   if projects_to_exclude is None:\n",
        "#     projects_to_exclude = []\n",
        "#   elif isinstance(projects_to_exclude, str):\n",
        "#     projects_to_exclude = [projects_to_exclude]\n",
        "\n",
        "#   projects_to_exclude = [p.lower() for p in projects_to_exclude]\n",
        "\n",
        "#   return \\\n",
        "#   {\n",
        "#     category_name:\n",
        "#     [\n",
        "#       constructor2(sentence, fmt, get_ancestors)\n",
        "#       for project_name, project_text in projects.items()\n",
        "#       for sentence in project_text\n",
        "#       if project_name.lower() not in projects_to_exclude\n",
        "#     ]\n",
        "#     for category_name, projects in _parsed_cat_proj.items()\n",
        "#   }\n",
        "\n",
        "\n",
        "# print(\n",
        "#   '\\n\\n=======================================\\n'\n",
        "#   + 'Use GetAllText() to get all text as a list.\\n'\n",
        "#   + 'Use GetTextByCategories() to get a dictionary with category names as\\n'\n",
        "#   + '  keys and lists of sentences belonging to that category as values.\\n'\n",
        "#   + '=======================================\\n'\n",
        "# )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQXus9F35j09",
        "cellView": "form"
      },
      "source": [
        "# @title\n",
        "from nltk.tree import Tree\n",
        "import numpy as np\n",
        "\n",
        "def FindLabelInTree(tree, label):\n",
        "  return [p for p in tree.treepositions() if isinstance(tree[p], nltk.tree.Tree) and label == tree[p].label()]\n",
        "\n",
        "def GetParseString(tree):\n",
        "  tree_copy = tree.copy(deep=True)\n",
        "  for lix in range(len(tree_copy.leaves())):\n",
        "    tree_copy[tree_copy.leaf_treeposition(lix)] = \\\n",
        "      tree_copy[tree_copy.leaf_treeposition(lix)].to_string(\"{originalText}\")\n",
        "  return str(tree_copy)\n",
        "\n",
        "def SwapPhrases(sentence_1, sentence_2, label):\n",
        "  # Build a tree from each sentence\n",
        "  tree_1 = sentence_1.makeParseTree()\n",
        "  tree_2 = sentence_2.makeParseTree()\n",
        "\n",
        "  # Find phrase in both trees\n",
        "  tree_1_phrases = FindLabelInTree(tree_1, label)\n",
        "  tree_2_phrases = FindLabelInTree(tree_2, label)\n",
        "\n",
        "  # If there is nothing to swap, return\n",
        "  if 0 == len(sentence_1_phrases) or 0 == len(sentence_2_phrases):\n",
        "    return (None, None)\n",
        "  \n",
        "  # Pick a phrase at random from each sentence\n",
        "  tree_1_index = tree_1_phrases[np.random.randint(len(tree_1_phrases))]\n",
        "  tree_2_index = tree_2_phrases[np.random.randint(len(tree_2_phrases))]\n",
        "\n",
        "  # Swap\n",
        "  swap = tree_1[tree_1_index]\n",
        "  tree_1[tree_1_index] = tree_2[tree_2_index]\n",
        "  tree_2[tree_2_index] = swap\n",
        "\n",
        "  # Create Sentences\n",
        "  #   Create copy, convert leaves to strings (lemma), and get parse string\n",
        "  return \\\n",
        "  (\n",
        "    Sentence({\"parse\": GetParseString(tree_1)}, sentence_1.fmt),\n",
        "    Sentence({\"parse\": GetParseString(tree_2)}, sentence_2.fmt)\n",
        "  )\n",
        "\n",
        "text = GetTextByCategories(word=\"word\", show_pos=False, keep_punctuation=False)\n",
        "\n",
        "s1 = text['aspect evaluation'][0]\n",
        "s1.fmt\n",
        "\n",
        "t1 = text['aspect evaluation'][0].makeParseTree()\n",
        "t2 = text['feature request'][0].makeParseTree()\n",
        "\n",
        "t1.pretty_print()\n",
        "t2.pretty_print()\n",
        "\n",
        "t1_np = FindLabelInTree(t1, \"NP\")\n",
        "t2_np = FindLabelInTree(t2, \"NP\")\n",
        "\n",
        "t1_np_ix = t1_np[np.random.randint(len(t1_np))]\n",
        "t2_np_ix = t2_np[np.random.randint(len(t2_np))]\n",
        "\n",
        "t2[t2_np_ix].pretty_print()\n",
        "\n",
        "swap = t1[t1_np_ix]\n",
        "t1[t1_np_ix] = t2[t2_np_ix]\n",
        "t2[t2_np_ix] = swap\n",
        "\n",
        "str(t1)\n",
        "\n",
        "t1.pretty_print()\n",
        "t2.pretty_print()\n",
        "\n",
        "t3 = t1.copy(deep=True)\n",
        "t3[t3.leaf_treeposition(0)] = 'a'\n",
        "t3.pretty_print()\n",
        "t1.pretty_print()\n",
        "# t1_tokens = t1.leaves()\n",
        "# print(str(t1))\n",
        "# print([token.to_string(\"{lemma}\") for token in t1.leaves()])\n",
        "# print([token.to_string(\"{lemma}\") for token in t2.leaves()])\n",
        "# print(str(t1))\n",
        "# print(GetParseString(t1))\n",
        "nltk.tree.Tree.fromstring(GetParseString(t1)).pretty_print()\n",
        "token = t1.leaves()[0]\n",
        "parse = GetParseString(t1)\n",
        "tokens = [t.properties for t in t1.leaves()]\n",
        "s = Sentence({\"parse\": parse, \"tokens\": tokens}, \"{word}\")\n",
        "print(s)\n",
        "\n",
        "# swap = t1[t1_np_ix]\n",
        "# t1.insert(t1_np_ix, t2[t2_np_ix])\n",
        "# t2.insert(t2_np_ix, t1[t1_np_ix])\n",
        "\n",
        "# t1.pretty_print()\n",
        "# t2.pretty_print()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}